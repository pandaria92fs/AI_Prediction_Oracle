

================================================================================
FILE: verify_api.py
================================================================================

"""API å“åº”ç»“æ„éªŒè¯è„šæœ¬"""
import sys
from typing import Any, Dict, Optional

import httpx


class Colors:
    """ç»ˆç«¯é¢œè‰²"""
    GREEN = "\033[92m"
    RED = "\033[91m"
    YELLOW = "\033[93m"
    RESET = "\033[0m"


def print_pass(message: str):
    """æ‰“å°é€šè¿‡ä¿¡æ¯"""
    print(f"{Colors.GREEN}âœ… PASS{Colors.RESET}: {message}")


def print_fail(message: str):
    """æ‰“å°å¤±è´¥ä¿¡æ¯"""
    print(f"{Colors.RED}âŒ FAIL{Colors.RESET}: {message}")


def print_info(message: str):
    """æ‰“å°ä¿¡æ¯"""
    print(f"{Colors.YELLOW}â„¹ï¸  INFO{Colors.RESET}: {message}")


def test_list_endpoint(base_url: str) -> Optional[str]:
    """
    æµ‹è¯• GET /card/list ç«¯ç‚¹
    
    Returns:
        è¿”å›ç¬¬ä¸€ä¸ªå¡ç‰‡çš„ IDï¼ˆç”¨äºåç»­æµ‹è¯•ï¼‰ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: GET /card/list")
    print("=" * 60)

    url = f"{base_url}/card/list"
    params = {"page": 1, "pageSize": 10}

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(url, params=params)
            response.raise_for_status()

            # æ–­è¨€ 1: çŠ¶æ€ç ä¸º 200
            if response.status_code != 200:
                print_fail(f"çŠ¶æ€ç åº”ä¸º 200ï¼Œå®é™…ä¸º {response.status_code}")
                return None
            print_pass(f"çŠ¶æ€ç : {response.status_code}")

            # è§£æ JSON
            data = response.json()

            # æ–­è¨€ 2: å“åº”ç»“æ„åŒ¹é…
            if "code" not in data or "message" not in data or "data" not in data:
                print_fail("å“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: code, message, data")
                return None
            print_pass("å“åº”åŒ…å« code, message, data å­—æ®µ")

            if data["code"] != 200:
                print_fail(f"code åº”ä¸º 200ï¼Œå®é™…ä¸º {data['code']}")
                return None
            print_pass(f"code: {data['code']}")

            # æ–­è¨€ 3: data ç»“æ„åŒ¹é… { total, page, pageSize, list }
            data_payload = data["data"]
            required_fields = ["total", "page", "pageSize", "list"]
            missing_fields = [f for f in required_fields if f not in data_payload]

            if missing_fields:
                print_fail(f"data ç¼ºå°‘å­—æ®µ: {missing_fields}")
                return None
            print_pass(f"data åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ: {required_fields}")

            # éªŒè¯å­—æ®µç±»å‹
            if not isinstance(data_payload["total"], int):
                print_fail(f"total åº”ä¸º intï¼Œå®é™…ä¸º {type(data_payload['total'])}")
                return None
            print_pass(f"total ç±»å‹æ­£ç¡®: {type(data_payload['total']).__name__}")

            if not isinstance(data_payload["list"], list):
                print_fail(f"list åº”ä¸º listï¼Œå®é™…ä¸º {type(data_payload['list'])}")
                return None
            print_pass(f"list ç±»å‹æ­£ç¡®: {type(data_payload['list']).__name__}")

            # æ–­è¨€ 4: æ£€æŸ¥åˆ—è¡¨é¡¹ä¸­çš„å­—æ®µ
            if len(data_payload["list"]) == 0:
                print_info("åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡å­—æ®µæ£€æŸ¥")
                return None

            first_item = data_payload["list"][0]

            # æ£€æŸ¥ icon å­—æ®µï¼ˆé‡å‘½åè‡ª imageUrlï¼‰
            if "icon" not in first_item:
                print_fail("åˆ—è¡¨é¡¹ç¼ºå°‘ 'icon' å­—æ®µ")
                return None
            print_pass("åˆ—è¡¨é¡¹åŒ…å« 'icon' å­—æ®µ")

            # æ£€æŸ¥ markets å­—æ®µ
            if "markets" not in first_item:
                print_fail("åˆ—è¡¨é¡¹ç¼ºå°‘ 'markets' å­—æ®µ")
                return None
            if not isinstance(first_item["markets"], list):
                print_fail(f"markets åº”ä¸º listï¼Œå®é™…ä¸º {type(first_item['markets'])}")
                return None
            print_pass("åˆ—è¡¨é¡¹åŒ…å« 'markets' å­—æ®µï¼ˆç±»å‹ä¸º listï¼‰")

            # æ£€æŸ¥ markets ä¸­çš„ probability å­—æ®µ
            if len(first_item["markets"]) > 0:
                first_market = first_item["markets"][0]
                if "probability" not in first_market:
                    print_fail("market é¡¹ç¼ºå°‘ 'probability' å­—æ®µ")
                    return None
                if not isinstance(first_market["probability"], (int, float)):
                    print_fail(
                        f"probability åº”ä¸ºæ•°å­—ï¼Œå®é™…ä¸º {type(first_market['probability'])}"
                    )
                    return None
                print_pass(
                    f"market é¡¹åŒ…å« 'probability' å­—æ®µ: {first_market['probability']}"
                )

            # è·å–ç¬¬ä¸€ä¸ªå¡ç‰‡çš„ ID ç”¨äºåç»­æµ‹è¯•
            card_id = first_item.get("id")
            if not card_id:
                print_fail("åˆ—è¡¨é¡¹ç¼ºå°‘ 'id' å­—æ®µ")
                return None
            print_pass(f"è·å–åˆ°ç¬¬ä¸€ä¸ªå¡ç‰‡ ID: {card_id}")

            print_info(f"åˆ—è¡¨æ€»æ•°: {data_payload['total']}")
            print_info(f"å½“å‰é¡µ: {data_payload['page']}")
            print_info(f"æ¯é¡µæ•°é‡: {data_payload['pageSize']}")
            print_info(f"å½“å‰é¡µé¡¹ç›®æ•°: {len(data_payload['list'])}")

            return card_id

    except httpx.HTTPStatusError as e:
        print_fail(f"HTTP é”™è¯¯: {e.response.status_code} - {e.response.text}")
        return None
    except httpx.RequestError as e:
        print_fail(f"è¯·æ±‚é”™è¯¯: {str(e)}")
        return None
    except Exception as e:
        print_fail(f"æœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        return None


def test_details_endpoint(base_url: str, card_id: str):
    """
    æµ‹è¯• GET /card/details ç«¯ç‚¹
    
    Args:
        base_url: API åŸºç¡€ URL
        card_id: å¡ç‰‡ ID
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: GET /card/details")
    print("=" * 60)

    url = f"{base_url}/card/details"
    params = {"id": card_id}

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(url, params=params)
            response.raise_for_status()

            # æ–­è¨€ 1: çŠ¶æ€ç ä¸º 200
            if response.status_code != 200:
                print_fail(f"çŠ¶æ€ç åº”ä¸º 200ï¼Œå®é™…ä¸º {response.status_code}")
                return
            print_pass(f"çŠ¶æ€ç : {response.status_code}")

            # è§£æ JSON
            data = response.json()

            # æ–­è¨€ 2: å“åº”ç»“æ„åŒ¹é…
            if "code" not in data or "message" not in data or "data" not in data:
                print_fail("å“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: code, message, data")
                return
            print_pass("å“åº”åŒ…å« code, message, data å­—æ®µ")

            if data["code"] != 200:
                print_fail(f"code åº”ä¸º 200ï¼Œå®é™…ä¸º {data['code']}")
                return
            print_pass(f"code: {data['code']}")

            # æ–­è¨€ 3: data ç»“æ„åŒ¹é… { id: str, ... }
            card_data = data["data"]

            if "id" not in card_data:
                print_fail("data ç¼ºå°‘ 'id' å­—æ®µ")
                return
            if not isinstance(card_data["id"], str):
                print_fail(f"id åº”ä¸º strï¼Œå®é™…ä¸º {type(card_data['id'])}")
                return
            print_pass(f"data åŒ…å« 'id' å­—æ®µ: {card_data['id']}")

            # æ–­è¨€ 4: æ£€æŸ¥ ai_analysis å­—æ®µï¼ˆå¯ä»¥ä¸º Noneï¼‰
            if "ai_analysis" not in card_data:
                print_fail("data ç¼ºå°‘ 'ai_analysis' å­—æ®µ")
                return
            print_pass(
                f"data åŒ…å« 'ai_analysis' å­—æ®µ: {card_data.get('ai_analysis', 'None')}"
            )

            # æ–­è¨€ 5: æ£€æŸ¥ createdAt å­—æ®µ
            if "createdAt" not in card_data:
                print_fail("data ç¼ºå°‘ 'createdAt' å­—æ®µ")
                return
            print_pass(f"data åŒ…å« 'createdAt' å­—æ®µ: {card_data.get('createdAt')}")

            print_info(f"å¡ç‰‡æ ‡é¢˜: {card_data.get('title', 'N/A')}")
            print_info(f"å¡ç‰‡ slug: {card_data.get('slug', 'N/A')}")

    except httpx.HTTPStatusError as e:
        print_fail(f"HTTP é”™è¯¯: {e.response.status_code} - {e.response.text}")
    except httpx.RequestError as e:
        print_fail(f"è¯·æ±‚é”™è¯¯: {str(e)}")
    except Exception as e:
        print_fail(f"æœªé¢„æœŸçš„é”™è¯¯: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    base_url = "http://127.0.0.1:8000"

    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å®ƒä½œä¸º base_url
    if len(sys.argv) > 1:
        base_url = sys.argv[1]

    print(f"\nğŸš€ å¼€å§‹éªŒè¯ API å“åº”ç»“æ„")
    print(f"ğŸ“ ç›®æ ‡ URL: {base_url}")

    # æµ‹è¯• 1: List ç«¯ç‚¹
    card_id = test_list_endpoint(base_url)

    # æµ‹è¯• 2: Details ç«¯ç‚¹ï¼ˆå¦‚æœ List æµ‹è¯•æˆåŠŸï¼‰
    if card_id:
        test_details_endpoint(base_url, card_id)
    else:
        print_fail("è·³è¿‡ Details æµ‹è¯•ï¼ˆList æµ‹è¯•å¤±è´¥ï¼‰")

    print("\n" + "=" * 60)
    print("âœ… éªŒè¯å®Œæˆ")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()


================================================================================
FILE: stitch_code.py
================================================================================

import os

OUTPUT_FILE = "all_code.txt"
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# ç®€å•å¿½ç•¥è¿™äº›ç›®å½•
IGNORE_DIRS = {".git", ".venv", "venv", "__pycache__", ".cursor"}

# è®¤ä¸ºæ˜¯â€œä»£ç æ–‡ä»¶â€çš„åç¼€ï¼ˆå¯æŒ‰éœ€å¢å‡ï¼‰
CODE_EXTS = {".py", ".sql", ".js", ".ts", ".tsx", ".json", ".yml", ".yaml"}

with open(os.path.join(PROJECT_ROOT, OUTPUT_FILE), "w", encoding="utf-8") as out:
    for root, dirs, files in os.walk(PROJECT_ROOT):
        # è¿‡æ»¤æ‰ä¸æƒ³éå†çš„ç›®å½•
        dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]

        for name in files:
            _, ext = os.path.splitext(name)
            if ext not in CODE_EXTS:
                continue

            path = os.path.join(root, name)
            rel_path = os.path.relpath(path, PROJECT_ROOT)

            out.write("\n\n" + "=" * 80 + "\n")
            out.write(f"FILE: {rel_path}\n")
            out.write("=" * 80 + "\n\n")

            try:
                with open(path, "r", encoding="utf-8") as f:
                    out.write(f.read())
            except Exception as e:
                out.write(f"<<æ— æ³•è¯»å–æ–‡ä»¶ {rel_path}: {e}>>\n")

================================================================================
FILE: migrations/env.py
================================================================================

import asyncio
from logging.config import fileConfig
import sys
from pathlib import Path
import os
from dotenv import load_dotenv # ç¡®ä¿å¼•å…¥

from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import async_engine_from_config
from alembic import context

# 1. è·¯å¾„è®¾ç½®
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

# 2. å¼ºåˆ¶åŠ è½½ .env
load_dotenv()

# è¯»å–é…ç½®
config = context.config

# 3. è·å– URL
db_url = os.environ.get("DATABASE_URL")

# --- ğŸ” è°ƒè¯•æ‰“å° (å…³é”®) ---
print(f"-------------- DEBUG INFO --------------")
print(f"åŸå§‹ URL: {db_url}")

if not db_url:
    raise ValueError("âŒ Error: DATABASE_URL is missing in .env!")

# 4. æš´åŠ›ä¿®å¤é€»è¾‘ (ä¸ç®¡å¼€å¤´æ˜¯ postgres è¿˜æ˜¯ postgresqlï¼Œç»Ÿç»ŸåŠ é©±åŠ¨)
if "asyncpg" not in db_url:
    print("âš ï¸ æ£€æµ‹åˆ° URL ç¼ºå°‘é©±åŠ¨ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨ä¿®å¤...")
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql+asyncpg://", 1)
    elif db_url.startswith("postgresql://"):
        db_url = db_url.replace("postgresql://", "postgresql+asyncpg://", 1)

print(f"æœ€ç»ˆ URL: {db_url}")
print(f"----------------------------------------")

# è®¾ç½®ç»™ Alembic
config.set_main_option("sqlalchemy.url", db_url)

# æ—¥å¿—é…ç½®
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# å¯¼å…¥ Base
try:
    from app.db.base import Base
except ImportError:
    from app.models import Base

target_metadata = Base.metadata

def run_migrations_offline() -> None:
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()

def do_run_migrations(connection: Connection) -> None:
    context.configure(connection=connection, target_metadata=target_metadata)
    with context.begin_transaction():
        context.run_migrations()

async def run_async_migrations() -> None:
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)
    await connectable.dispose()

def run_migrations_online() -> None:
    asyncio.run(run_async_migrations())

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

================================================================================
FILE: migrations/add_performance_indexes.sql
================================================================================

-- =====================================================
-- æ€§èƒ½ä¼˜åŒ–ç´¢å¼•åˆ›å»ºè„šæœ¬
-- åœ¨ Supabase SQL Editor ä¸­æ‰§è¡Œæ­¤è„šæœ¬
-- =====================================================

-- 1. event_snapshots(polymarket_id) ç´¢å¼•ï¼ˆå…³é”®ï¼šä¿®å¤ 10s å»¶è¿Ÿï¼‰
-- æ³¨æ„ï¼šå¦‚æœå·²æœ‰å¤åˆç´¢å¼•ï¼Œè¿™ä¸ªå•åˆ—ç´¢å¼•å¯èƒ½ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¯ä»¥åŠ é€Ÿå•åˆ—æŸ¥è¯¢
CREATE INDEX IF NOT EXISTS idx_event_snapshots_polymarket_id 
ON event_snapshots(polymarket_id);

-- 2. event_cards(is_active) ç´¢å¼•ï¼ˆç”¨äºè¿‡æ»¤æ´»è·ƒå¡ç‰‡ï¼‰
CREATE INDEX IF NOT EXISTS idx_event_cards_is_active 
ON event_cards(is_active) 
WHERE is_active = true;  -- éƒ¨åˆ†ç´¢å¼•ï¼Œåªç´¢å¼•æ´»è·ƒçš„å¡ç‰‡

-- 3. event_cards(volume) ç´¢å¼•ï¼ˆç”¨äºæ’åºï¼‰
CREATE INDEX IF NOT EXISTS idx_event_cards_volume 
ON event_cards(volume DESC NULLS LAST);

-- 4. å¤åˆç´¢å¼•ï¼šis_active + volumeï¼ˆä¼˜åŒ–å¸¸è§æŸ¥è¯¢æ¨¡å¼ï¼‰
CREATE INDEX IF NOT EXISTS idx_event_cards_active_volume 
ON event_cards(is_active, volume DESC NULLS LAST) 
WHERE is_active = true;

-- 5. ä¼˜åŒ– event_snapshots çš„å¤åˆç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
-- ç”¨äº DISTINCT ON æŸ¥è¯¢ï¼šæŒ‰ polymarket_id åˆ†ç»„ï¼Œå–æœ€æ–°çš„ created_at
CREATE INDEX IF NOT EXISTS idx_event_snapshots_polymarket_created 
ON event_snapshots(polymarket_id, created_at DESC);

-- =====================================================
-- éªŒè¯ç´¢å¼•æ˜¯å¦åˆ›å»ºæˆåŠŸ
-- =====================================================
-- SELECT 
--     schemaname,
--     tablename,
--     indexname,
--     indexdef
-- FROM pg_indexes
-- WHERE tablename IN ('event_cards', 'event_snapshots')
-- ORDER BY tablename, indexname;


================================================================================
FILE: migrations/versions/7c2b2efee74e_init_v2_architecture.py
================================================================================

"""init_v2_architecture

Revision ID: 7c2b2efee74e
Revises: 
Create Date: 2026-01-27 14:52:53.943233

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '7c2b2efee74e'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('event_cards',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('polymarket_id', sa.String(length=50), nullable=False),
    sa.Column('title', sa.String(length=500), nullable=False),
    sa.Column('slug', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('image_url', sa.String(length=1000), nullable=True),
    sa.Column('volume', sa.Numeric(precision=20, scale=2), nullable=True),
    sa.Column('end_date', sa.DateTime(timezone=True), nullable=True),
    sa.Column('is_active', sa.Boolean(), server_default='true', nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_event_cards_polymarket_id'), 'event_cards', ['polymarket_id'], unique=True)
    op.create_index(op.f('ix_event_cards_slug'), 'event_cards', ['slug'], unique=True)
    op.create_table('event_snapshots',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('polymarket_id', sa.String(length=50), nullable=False),
    sa.Column('raw_data', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_event_snapshots_polymarket_id'), 'event_snapshots', ['polymarket_id'], unique=False)
    op.create_index('ix_event_snapshots_polymarket_id_created_at', 'event_snapshots', ['polymarket_id', 'created_at'], unique=False)
    op.create_table('tags',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('name')
    )
    op.create_table('ai_predictions',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('card_id', sa.BigInteger(), nullable=False),
    sa.Column('summary', sa.Text(), nullable=False),
    sa.Column('confidence_score', sa.Numeric(precision=5, scale=2), nullable=False),
    sa.Column('outcome_prediction', sa.String(length=255), nullable=False),
    sa.Column('raw_analysis', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['card_id'], ['event_cards.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_ai_predictions_card_id'), 'ai_predictions', ['card_id'], unique=False)
    op.create_index(op.f('ix_ai_predictions_created_at'), 'ai_predictions', ['created_at'], unique=False)
    op.create_table('card_tags',
    sa.Column('card_id', sa.BigInteger(), nullable=False),
    sa.Column('tag_id', sa.BigInteger(), nullable=False),
    sa.ForeignKeyConstraint(['card_id'], ['event_cards.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['tag_id'], ['tags.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('card_id', 'tag_id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('card_tags')
    op.drop_index(op.f('ix_ai_predictions_created_at'), table_name='ai_predictions')
    op.drop_index(op.f('ix_ai_predictions_card_id'), table_name='ai_predictions')
    op.drop_table('ai_predictions')
    op.drop_table('tags')
    op.drop_index('ix_event_snapshots_polymarket_id_created_at', table_name='event_snapshots')
    op.drop_index(op.f('ix_event_snapshots_polymarket_id'), table_name='event_snapshots')
    op.drop_table('event_snapshots')
    op.drop_index(op.f('ix_event_cards_slug'), table_name='event_cards')
    op.drop_index(op.f('ix_event_cards_polymarket_id'), table_name='event_cards')
    op.drop_table('event_cards')
    # ### end Alembic commands ###


================================================================================
FILE: app/__init__.py
================================================================================

"""AI Prediction Oracle Backend Application"""


================================================================================
FILE: app/main.py
================================================================================

"""FastAPI åº”ç”¨ä¸»å…¥å£"""
from typing import Optional

from fastapi import BackgroundTasks, Depends, FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import bindparam, desc, select, text
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.api.endpoints import cards
from app.core.config import settings
from app.db.session import get_db
from app.models.event_card import EventCard
from app.models.event_snapshot import EventSnapshot
from app.services.crawler import run_batch_crawl

app = FastAPI(
    title=settings.PROJECT_NAME,
    version=settings.VERSION,
    description="AI Prediction Oracle Backend API",
)

# CORS é…ç½® - å…è®¸å‰ç«¯è·¨åŸŸè®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰ HTTP æ–¹æ³•
    allow_headers=["*"],  # å¿…é¡»æ˜¯ "*" æˆ–åŒ…å« "ngrok-skip-browser-warning"
)

# æ³¨å†Œè·¯ç”±
# è·¯ç”±è·¯å¾„: /card/list, /card/details
app.include_router(
    cards.router,
    prefix="/card",
    tags=["Cards"],
)


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    print("ğŸš€ Polymarket Backend Ready")
    print(f"ğŸ“š API Documentation: http://localhost:8000/docs")
    print(f"ğŸ” ReDoc: http://localhost:8000/redoc")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "AI Prediction Oracle API",
        "version": settings.VERSION,
        "docs": "/docs",
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}


@app.get("/api/v1/cards")
async def get_cards(
    page: int = Query(1, ge=1, description="é¡µç "),
    pageSize: int = Query(20, ge=1, description="æ¯é¡µæ•°é‡"),
    tag_id: Optional[str] = Query(None, description="ç¬¬ä¸‰æ–¹æ ‡ç­¾ ID è¿‡æ»¤ï¼ˆPolymarket çš„ tag idï¼‰"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    - **page**: é¡µç ï¼ˆä» 1 å¼€å§‹ï¼‰
    - **pageSize**: æ¯é¡µæ•°é‡
    - **tag_id**: å¯é€‰çš„ç¬¬ä¸‰æ–¹æ ‡ç­¾ ID è¿‡æ»¤ï¼ˆä» Polymarket API çš„ raw_data.tags ä¸­è·å–ï¼‰
    """
    offset = (page - 1) * pageSize
    
    # æ„å»ºåŸºç¡€æŸ¥è¯¢ï¼Œé¢„åŠ è½½ predictions å…³ç³»
    query = (
        select(EventCard)
        .options(selectinload(EventCard.predictions))
        .where(EventCard.is_active == True)
    )
    
    # å¦‚æœä¼ äº† tag_idï¼Œä» EventSnapshot çš„ raw_data JSONB ä¸­è¿‡æ»¤
    # ä½¿ç”¨ PostgreSQL çš„ JSONB æŸ¥è¯¢ï¼šæ£€æŸ¥ tags æ•°ç»„ä¸­æ˜¯å¦æœ‰ id åŒ¹é…çš„å…ƒç´ 
    if tag_id:
        # JOIN EventSnapshot è¡¨ï¼Œå¹¶ä½¿ç”¨ JSONB æŸ¥è¯¢æ¡ä»¶
        # æ£€æŸ¥ raw_data->'tags' æ•°ç»„ä¸­æ˜¯å¦æœ‰ä»»ä½•ä¸€ä¸ª tag çš„ id ç­‰äºä¼ å…¥çš„ tag_id
        # æ³¨æ„ï¼štags æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ {id, label, slug, ...} å¯¹è±¡
        query = query.join(
            EventSnapshot,
            EventCard.polymarket_id == EventSnapshot.polymarket_id
        ).where(
            text("""
                EXISTS (
                    SELECT 1 
                    FROM jsonb_array_elements(event_snapshots.raw_data->'tags') AS tag
                    WHERE tag->>'id' = :tag_id
                )
            """).bindparams(bindparam("tag_id", tag_id))
        ).distinct()
    
    # åŠ ä¸Šåˆ†é¡µå’Œæ’åº
    query = query.offset(offset).limit(pageSize).order_by(desc(EventCard.created_at))
    
    result = await db.execute(query)
    cards = result.scalars().all()
    
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ŒåŒ…å« aiLogicSummary å­—æ®µ
    cards_data = []
    for card in cards:
        card_dict = {
            "id": card.polymarket_id,
            "slug": card.slug,
            "title": card.title,
            "description": card.description,
            "image_url": card.image_url,
            "volume": float(card.volume) if card.volume else None,
            "end_date": card.end_date.isoformat() if card.end_date else None,
            "is_active": card.is_active,
            "created_at": card.created_at.isoformat() if card.created_at else None,
            "updated_at": card.updated_at.isoformat() if card.updated_at else None,
            "aiLogicSummary": None,  # é»˜è®¤å€¼
        }
        
        # ä» predictions ä¸­å–æœ€æ–°çš„ summary ä½œä¸º aiLogicSummary
        # predictions å·²ç»æŒ‰ created_at é™åºæ’åºï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ªå°±æ˜¯æœ€æ–°çš„
        if card.predictions and len(card.predictions) > 0:
            latest_prediction = card.predictions[0]
            card_dict["aiLogicSummary"] = latest_prediction.summary
        
        cards_data.append(card_dict)
    
    return cards_data


@app.post("/api/admin/trigger-update")
async def trigger_update(background_tasks: BackgroundTasks, secret: str):
    """
    è§¦å‘åå°çˆ¬è™«æ›´æ–°ä»»åŠ¡
    
    - **secret**: å¯†ç ä¿æŠ¤ï¼ˆé˜²æ­¢æœªæˆæƒè®¿é—®ï¼‰
    """
    # ç®€å•çš„å¯†ç ä¿æŠ¤ï¼Œé˜²æ­¢è·¯äººä¹±ç‚¹
    if secret != "my_super_secret_password":
        return {"error": "å¯†ç é”™è¯¯"}

    # å°†çˆ¬è™«ä»»åŠ¡åŠ å…¥åå°é˜Ÿåˆ—
    background_tasks.add_task(run_batch_crawl)

    return {"message": "å·²è§¦å‘åå°æ›´æ–°ä»»åŠ¡ï¼Œè¯·ç¨åæŸ¥çœ‹æ—¥å¿—"}


================================================================================
FILE: app/core/config.py
================================================================================

"""åº”ç”¨é…ç½®ç®¡ç†æ¨¡å—"""
from typing import Optional

from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """åº”ç”¨é…ç½®ç±»ï¼Œä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""

    # æ•°æ®åº“é…ç½®
    DATABASE_URL: str = "postgresql+asyncpg://user:password@localhost:5432/dbname"
    
    # API é…ç½®
    API_V1_PREFIX: str = "/api/v1"
    PROJECT_NAME: str = "AI Prediction Oracle"
    VERSION: str = "0.1.0"
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = "INFO"
    
    # CORS é…ç½®
    CORS_ORIGINS: list[str] = ["*"]
    
    # å…¶ä»–é…ç½®
    DEBUG: bool = False

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=True,
        extra="ignore",
    )


settings = Settings()


================================================================================
FILE: app/core/__init__.py
================================================================================

"""æ ¸å¿ƒæ¨¡å—"""


================================================================================
FILE: app/core/decorators.py
================================================================================

"""æ€§èƒ½åˆ†æè£…é¥°å™¨"""
import time
from functools import wraps
from typing import Callable, Any


def profile_endpoint(func: Callable) -> Callable:
    """
    æ€§èƒ½åˆ†æè£…é¥°å™¨ï¼Œç”¨äºæµ‹é‡ API ç«¯ç‚¹çš„æ‰§è¡Œæ—¶é—´
    
    è®°å½•ï¼š
    - SQL æ‰§è¡Œå’Œä¸šåŠ¡é€»è¾‘è€—æ—¶
    - æ€»é€»è¾‘è€—æ—¶
    """
    @wraps(func)
    async def wrapper(*args, **kwargs) -> Any:
        # 1. DB å‡†å¤‡è€—æ—¶è®°å½• (é€šè¿‡ contextvars æˆ–æ‰‹åŠ¨æ ‡è®°)
        start_time = time.perf_counter()
        
        # æ‰§è¡Œä¸šåŠ¡é€»è¾‘ (DB æŸ¥è¯¢)
        db_start = time.perf_counter()
        result = await func(*args, **kwargs)
        db_end = time.perf_counter()
        
        # 2. åºåˆ—åŒ–è€—æ—¶è®°å½• (FastAPI åœ¨è¿”å› Response æ—¶å¤„ç†åºåˆ—åŒ–)
        # æ³¨æ„ï¼šæ­¤å¤„è®°å½•çš„æ˜¯é€»è¾‘è¿”å›åçš„æ—¶é—´ç‚¹
        print(f"--- Profiling: {func.__name__} ---")
        print(f"SQL Execution & Logic: {(db_end - db_start):.4f}s")
        print(f"Total Logic Duration: {(time.perf_counter() - start_time):.4f}s")
        
        return result
    return wrapper


================================================================================
FILE: app/models/ai_prediction.py
================================================================================

"""Intelligence Layer: AIPrediction"""

from __future__ import annotations

from datetime import datetime
from decimal import Decimal
from typing import Optional

from sqlalchemy import BigInteger, DateTime, ForeignKey, Numeric, String, Text, func
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.db.base import Base


class AIPrediction(Base):
    __tablename__ = "ai_predictions"

    id: Mapped[int] = mapped_column(BigInteger, primary_key=True, autoincrement=True)
    card_id: Mapped[int] = mapped_column(
        BigInteger,
        ForeignKey("event_cards.id", ondelete="CASCADE"),
        nullable=False,
        index=True,
    )

    summary: Mapped[str] = mapped_column(Text, nullable=False)
    confidence_score: Mapped[Decimal] = mapped_column(Numeric(5, 2), nullable=False)
    outcome_prediction: Mapped[str] = mapped_column(String(255), nullable=False)
    raw_analysis: Mapped[Optional[str]] = mapped_column(Text, nullable=True)

    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        nullable=False,
        server_default=func.now(),
        index=True,
    )

    card: Mapped["EventCard"] = relationship(
        "EventCard",
        back_populates="predictions",
        lazy="selectin",
    )


================================================================================
FILE: app/models/__init__.py
================================================================================

"""æ•°æ®åº“æ¨¡å‹æ¨¡å—ï¼ˆApplication-First Schemaï¼‰"""

from app.models.ai_prediction import AIPrediction
from app.models.card_tag import CardTag, card_tags
from app.models.event_card import EventCard
from app.models.event_snapshot import EventSnapshot
from app.models.tag import Tag

__all__ = [
    "EventSnapshot",
    "EventCard",
    "Tag",
    "CardTag",
    "card_tags",
    "AIPrediction",
]


================================================================================
FILE: app/models/event_snapshot.py
================================================================================

"""Raw Data Layer: EventSnapshot"""

from __future__ import annotations

from datetime import datetime

from sqlalchemy import BigInteger, DateTime, Index, String, func
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import Mapped, mapped_column

from app.db.base import Base


class EventSnapshot(Base):
    __tablename__ = "event_snapshots"

    id: Mapped[int] = mapped_column(BigInteger, primary_key=True, autoincrement=True)
    polymarket_id: Mapped[str] = mapped_column(String(50), index=True, nullable=False)
    raw_data: Mapped[dict] = mapped_column(JSONB, nullable=False)

    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        nullable=False,
        server_default=func.now(),
    )

    __table_args__ = (
        Index("ix_event_snapshots_polymarket_id_created_at", "polymarket_id", "created_at"),
    )



================================================================================
FILE: app/models/card_tag.py
================================================================================

"""EventCard <-> Tag å…³è”è¡¨"""

from sqlalchemy import BigInteger, Column, ForeignKey, Table
from sqlalchemy.orm import Mapped

from app.db.base import Base

card_tags = Table(
    "card_tags",
    Base.metadata,
    Column(
        "card_id",
        BigInteger,
        ForeignKey("event_cards.id", ondelete="CASCADE"),
        primary_key=True,
    ),
    Column(
        "tag_id",
        BigInteger,
        ForeignKey("tags.id", ondelete="CASCADE"),
        primary_key=True,
    ),
)


class CardTag(Base):
    """card_tags çš„ ORM æ˜ å°„ï¼ˆä¾¿äºæŸ¥è¯¢/æ’å…¥ï¼‰"""

    __table__ = card_tags

    # typing only (åˆ—æ¥è‡ª __table__)
    card_id: Mapped[int]
    tag_id: Mapped[int]



================================================================================
FILE: app/models/event_card.py
================================================================================

"""Presentation Layer: EventCard"""

from __future__ import annotations

from datetime import datetime
from decimal import Decimal
from typing import List, Optional

from sqlalchemy import BigInteger, Boolean, DateTime, Numeric, String, Text, func
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.db.base import Base
from app.models.card_tag import card_tags


class EventCard(Base):
    __tablename__ = "event_cards"

    id: Mapped[int] = mapped_column(BigInteger, primary_key=True, autoincrement=True)

    polymarket_id: Mapped[str] = mapped_column(
        String(50),
        unique=True,
        index=True,
        nullable=False,
    )

    title: Mapped[str] = mapped_column(String(500), nullable=False)
    slug: Mapped[str] = mapped_column(String(255), unique=True, index=True, nullable=False)

    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
    image_url: Mapped[Optional[str]] = mapped_column(String(1000), nullable=True)

    volume: Mapped[Optional[Decimal]] = mapped_column(Numeric(20, 2), nullable=True)
    end_date: Mapped[Optional[datetime]] = mapped_column(DateTime(timezone=True), nullable=True)

    is_active: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default="true")

    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        nullable=False,
        server_default=func.now(),
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        nullable=False,
        server_default=func.now(),
        onupdate=func.now(),
    )

    # Relationships
    tags: Mapped[List["Tag"]] = relationship(
        "Tag",
        secondary=card_tags,
        back_populates="cards",
        lazy="selectin",
    )
    predictions: Mapped[List["AIPrediction"]] = relationship(
        "AIPrediction",
        back_populates="card",
        cascade="all, delete-orphan",
        lazy="selectin",
        order_by="desc(AIPrediction.created_at)",
    )



================================================================================
FILE: app/models/tag.py
================================================================================

"""Tag æ¨¡å‹"""

from __future__ import annotations

from typing import List

from sqlalchemy import BigInteger, String
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.db.base import Base
from app.models.card_tag import card_tags


class Tag(Base):
    __tablename__ = "tags"

    id: Mapped[int] = mapped_column(BigInteger, primary_key=True, autoincrement=True)
    name: Mapped[str] = mapped_column(String(255), unique=True, nullable=False)

    cards: Mapped[List["EventCard"]] = relationship(
        "EventCard",
        secondary=card_tags,
        back_populates="tags",
        lazy="selectin",
    )


================================================================================
FILE: app/schemas/__init__.py
================================================================================

"""Pydantic æ¨¡å¼å®šä¹‰"""


================================================================================
FILE: app/schemas/card.py
================================================================================

"""Card API çš„ Pydantic æ¨¡å¼å®šä¹‰"""
import json
from datetime import datetime
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field, field_validator, model_validator


class TagItem(BaseModel):
    """æ ‡ç­¾é¡¹"""

    id: str
    label: str
    slug: str

    class Config:
        populate_by_name = True
        from_attributes = True


class MarketItem(BaseModel):
    """å¸‚åœºé¡¹ï¼ˆä» raw_data ä¸­æå–ï¼‰"""

    id: str
    question: str
    outcomes: List[str]
    currentPrices: Dict[str, float] = Field(alias="currentPrices")
    volume: Optional[float] = None
    liquidity: Optional[float] = None
    active: bool = True

    # æ–°å¢å­—æ®µï¼ˆæŒ‰å‰ç«¯ Mock è¦æ±‚ï¼‰
    probability: float = 0.0
    adjustedProbability: float = 0.0
    tagIds: List[str] = []
    groupItemTitle: Optional[str] = None
    icon: Optional[str] = None
    archived: bool = False

    @field_validator("outcomes", mode="before")
    @classmethod
    def parse_outcomes_json(cls, v):
        """è§£æ outcomes JSON å­—ç¬¦ä¸²ä¸ºåˆ—è¡¨"""
        if isinstance(v, str):
            try:
                parsed = json.loads(v)
                return parsed if isinstance(parsed, list) else []
            except (json.JSONDecodeError, TypeError, ValueError):
                return []
        return v if isinstance(v, list) else []

    @field_validator("currentPrices", mode="before")
    @classmethod
    def parse_current_prices_json(cls, v):
        """è§£æ currentPrices JSON å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        if isinstance(v, str):
            try:
                parsed = json.loads(v)
                return parsed if isinstance(parsed, dict) else {}
            except (json.JSONDecodeError, TypeError, ValueError):
                return {}
        return v if isinstance(v, dict) else {}

    @model_validator(mode="before")
    @classmethod
    def compute_probabilities(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä» outcomePricesï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰è®¡ç®— probability å’Œ adjustedProbability
        - outcomePrices ä¾‹å¦‚: ["0.85", "0.15"] æˆ– '["0.85", "0.15"]'
        """
        outcome_prices = values.get("outcomePrices")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆå°è¯•è§£æä¸ºåˆ—è¡¨
        if isinstance(outcome_prices, str):
            try:
                outcome_prices = json.loads(outcome_prices)
            except (json.JSONDecodeError, TypeError, ValueError):
                outcome_prices = []

        prob = 0.0
        if isinstance(outcome_prices, (list, tuple)) and outcome_prices:
            try:
                prob = float(outcome_prices[0])
            except (TypeError, ValueError):
                prob = 0.0

        values["probability"] = prob
        values["adjustedProbability"] = prob
        return values

    class Config:
        populate_by_name = True
        from_attributes = True


class CardData(BaseModel):
    """å¡ç‰‡æ•°æ®"""

    id: str  # å…¬å¼€çš„ IDï¼Œå¯¹åº” polymarket_id
    slug: str
    title: str
    description: Optional[str] = None
    # å‰ç«¯å­—æ®µåä¸º iconï¼ŒORM å­—æ®µä¸º image_url
    icon: Optional[str] = Field(default=None, validation_alias="image_url")
    volume: Optional[float] = None
    liquidity: Optional[float] = None
    active: bool = True
    closed: bool = False
    startDate: Optional[str] = None
    endDate: Optional[str] = None
    createdAt: Optional[datetime] = None
    updatedAt: Optional[datetime] = None
    # é¢„ç•™ AI åˆ†æå­—æ®µï¼Œæ–¹ä¾¿åç»­æ‰©å±•
    ai_analysis: Optional[str] = None

    tags: List[TagItem] = []
    markets: List[MarketItem] = []

    @model_validator(mode="after")
    def process_markets(self) -> "CardData":
        """
        åŒæ­¥æ ‡ç­¾åˆ° marketsï¼Œå¹¶å¯¹ markets è¿›è¡Œè¿‡æ»¤ä¸æ’åºï¼š
        1. å°†çˆ¶çº§ tags çš„ id åŒæ­¥åˆ°æ¯ä¸ª market çš„ tagIdsï¼ˆå¦‚æœå…¶ä¸ºç©ºï¼‰
        2. ä»…ä¿ç•™ active=True ä¸” archived=False çš„ markets
        3. æŒ‰ probability é™åºæ’åºï¼Œvolume ä½œä¸ºæ¬¡çº§æ’åºé”®
        """
        if not self.markets:
            return self

        # 1. Sync Tags: å°†çˆ¶çº§ tags çš„ id åŒæ­¥åˆ° market.tagIds
        if self.tags:
            tag_ids = [t.id for t in self.tags]
            for m in self.markets:
                if not m.tagIds:
                    m.tagIds = tag_ids

        # 2. è¿‡æ»¤ï¼šä»…ä¿ç•™ active=True ä¸” archived=False çš„ markets
        valid_markets: List[MarketItem] = [
            m
            for m in self.markets
            if m.active is True and getattr(m, "archived", False) is False
        ]

        # 3. æ’åºï¼šæŒ‰ probability é™åºï¼Œvolume ä¸ºæ¬¡çº§æ’åºé”®
        valid_markets.sort(
            key=lambda x: (x.probability, x.volume or 0.0),
            reverse=True,
        )

        self.markets = valid_markets
        return self

    class Config:
        populate_by_name = True
        from_attributes = True


class StandardResponse(BaseModel):
    """æ ‡å‡† API å“åº”æ ¼å¼"""

    code: int = 200
    message: str = "success"
    data: Any = None

    class Config:
        populate_by_name = True
        from_attributes = True


class CardListPayload(BaseModel):
    """å¡ç‰‡åˆ—è¡¨æ•°æ®è½½ä½“ï¼Œç¬¦åˆå‰ç«¯æœŸæœ›ç»“æ„"""

    total: int
    page: int
    pageSize: int
    list: List[CardData]

    class Config:
        populate_by_name = True
        from_attributes = True


class CardListResponse(StandardResponse):
    """å¡ç‰‡åˆ—è¡¨å“åº”"""

    data: CardListPayload


class CardDetailsResponse(StandardResponse):
    """å¡ç‰‡è¯¦æƒ…å“åº”"""

    data: CardData


================================================================================
FILE: app/db/session.py
================================================================================

"""å¼‚æ­¥æ•°æ®åº“ä¼šè¯ç®¡ç†æ¨¡å—"""
from typing import AsyncGenerator

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)

from app.core.config import settings

# åˆ›å»ºå¼‚æ­¥å¼•æ“
engine = create_async_engine(
    settings.DATABASE_URL,
    echo=False,
    future=True,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    # å…³é”®ä¿®æ­£ï¼šå‚æ•°åæ˜¯ statement_cache_sizeï¼Œç¦ç”¨ç¼“å­˜ä»¥å…¼å®¹ Supabase è¿æ¥æ± ï¼ˆ6543 ç«¯å£ï¼‰
    connect_args={"statement_cache_size": 0},
)

# åˆ›å»ºå¼‚æ­¥ä¼šè¯å·¥å‚
AsyncSessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,
    autoflush=False,
)

# å…¼å®¹åˆ«åï¼šç»™ services/crawler.py ä½¿ç”¨
async_session_factory = AsyncSessionLocal


async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """
    æ•°æ®åº“ä¼šè¯ä¾èµ–æ³¨å…¥å‡½æ•°
    
    Yields:
        AsyncSession: å¼‚æ­¥æ•°æ®åº“ä¼šè¯
    """
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()


================================================================================
FILE: app/db/__init__.py
================================================================================

"""æ•°æ®åº“æ¨¡å—"""


================================================================================
FILE: app/db/base.py
================================================================================

"""æ•°æ®åº“åŸºç±»å’Œæ¨¡å‹å¯¼å…¥æ¨¡å—"""
from sqlalchemy.orm import DeclarativeBase

class Base(DeclarativeBase):
    """SQLAlchemy 2.0 Declarative Base"""


__all__ = ["Base"]


================================================================================
FILE: app/api/__init__.py
================================================================================

"""API è·¯ç”±æ¨¡å—"""


================================================================================
FILE: app/api/endpoints/cards.py
================================================================================

"""Card API ç«¯ç‚¹"""
import time
from typing import Optional

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import desc, func, select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.decorators import profile_endpoint
from app.db.session import get_db
from app.models.card_tag import card_tags
from app.models.event_card import EventCard
from app.models.event_snapshot import EventSnapshot
from app.models.tag import Tag
from app.schemas.card import (
    CardData,
    CardDetailsResponse,
    CardListPayload,
    CardListResponse,
)

router = APIRouter()


def _extract_markets_from_raw_data(raw_data: dict) -> list:
    """ä» raw_data ä¸­æå– markets åˆ—è¡¨"""
    markets = raw_data.get("markets", [])
    result = []
    for market in markets:
        # æå–æ‰€æœ‰å…³é”®å­—æ®µï¼ŒåŒ…æ‹¬æ–°å¢çš„å­—æ®µ
        market_data = {
            "id": market.get("id", ""),
            "question": market.get("question", ""),
            "outcomes": market.get("outcomes", []),
            "currentPrices": market.get("currentPrices", {}),
            "volume": market.get("volume"),
            "liquidity": market.get("liquidity"),  # Market çº§åˆ«çš„ liquidity
            "active": market.get("active", True),
            # æ–°å¢å­—æ®µï¼ˆå‰ç«¯ Mock è¦æ±‚ï¼‰
            "groupItemTitle": market.get("groupItemTitle"),  # ä¿®å¤ï¼šæ·»åŠ  groupItemTitle
            "icon": market.get("icon"),  # Market çº§åˆ«çš„ iconï¼ˆå¦‚æœæœ‰ï¼‰
            "outcomePrices": market.get("outcomePrices"),  # ä¿®å¤ï¼šæ·»åŠ  outcomePricesï¼ˆç”¨äºè®¡ç®— probabilityï¼‰
        }
        result.append(market_data)
    return result


def _extract_tags_from_raw_data(raw_data: dict) -> list:
    """ä» raw_data ä¸­æå– tags åˆ—è¡¨"""
    tags = raw_data.get("tags", [])
    result = []
    for tag in tags:
        result.append({
            "id": str(tag.get("id", "")),
            "label": tag.get("label", ""),
            "slug": tag.get("slug", ""),
        })
    return result


def _build_card_data(card: EventCard, snapshot: Optional[EventSnapshot] = None) -> dict:
    """æ„å»ºå¡ç‰‡æ•°æ®å¯¹è±¡"""
    raw_data = snapshot.raw_data if snapshot else {}
    
    # æ ¼å¼åŒ–æ—¥æœŸå­—æ®µ
    def format_date(date_value):
        """æ ¼å¼åŒ–æ—¥æœŸä¸º ISO å­—ç¬¦ä¸²"""
        if date_value is None:
            return None
        if isinstance(date_value, str):
            return date_value
        # å¦‚æœæ˜¯ datetime å¯¹è±¡ï¼Œè½¬æ¢ä¸º ISO æ ¼å¼
        return date_value.isoformat() if hasattr(date_value, 'isoformat') else str(date_value)
    
    # åŸºç¡€å­—æ®µä» EventCard è·å–ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ raw_data ä¸­çš„æœ€æ–°å€¼
    # ä¿®å¤ï¼šicon å­—æ®µæ˜ å°„ - ä½¿ç”¨ validation_aliasï¼Œæ‰€ä»¥è¿™é‡Œç”¨ image_url
    card_dict = {
        "id": card.polymarket_id,  # ä½¿ç”¨ id ä½œä¸ºå…¬å¼€å­—æ®µå
        "slug": card.slug,
        "title": card.title,
        "description": card.description or raw_data.get("description"),
        "image_url": card.image_url or raw_data.get("image") or raw_data.get("icon"),  # ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ imageï¼Œå…¶æ¬¡ icon
        "volume": float(card.volume) if card.volume else (float(raw_data.get("volume", 0)) if raw_data.get("volume") else None),
        "liquidity": float(raw_data.get("liquidity", 0)) if raw_data.get("liquidity") else None,
        "active": card.is_active,
        "closed": raw_data.get("closed", False),
        "startDate": format_date(raw_data.get("startDate")),
        "endDate": format_date(raw_data.get("endDate")) or format_date(card.end_date),
        "createdAt": card.created_at.isoformat() if card.created_at else None,  # ä¿®å¤ï¼šæ·»åŠ  createdAt
        "updatedAt": card.updated_at.isoformat() if card.updated_at else None,  # ä¿®å¤ï¼šæ·»åŠ  updatedAt
        "tags": _extract_tags_from_raw_data(raw_data),
        "markets": _extract_markets_from_raw_data(raw_data),
        "ai_analysis": None,  # é¢„ç•™å­—æ®µï¼Œå½“å‰ä¸º None
    }
    return card_dict


@router.get("/list", response_model=CardListResponse)
@profile_endpoint
async def get_card_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    pageSize: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    tagId: Optional[str] = Query(None, description="æ ‡ç­¾ ID è¿‡æ»¤"),
    sortBy: str = Query("volume", pattern="^(volume|liquidity)$", description="æ’åºå­—æ®µ"),
    order: str = Query("desc", pattern="^(asc|desc)$", description="æ’åºæ–¹å‘"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡åˆ—è¡¨
    
    - **page**: é¡µç ï¼ˆä» 1 å¼€å§‹ï¼‰
    - **pageSize**: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - **tagId**: å¯é€‰çš„æ ‡ç­¾ ID è¿‡æ»¤
    - **sortBy**: æ’åºå­—æ®µï¼ˆvolume æˆ– liquidityï¼‰
    - **order**: æ’åºæ–¹å‘ï¼ˆasc æˆ– descï¼‰
    """
    print(f"\nâ±ï¸ === å¼€å§‹è¯¦ç»†æ€§èƒ½è¯Šæ–­ (Page: {page}, PageSize: {pageSize}) ===")
    overall_start = time.perf_counter()

    try:
        # -------- 1. æ„å»ºåŸºç¡€æŸ¥è¯¢ï¼ˆç”¨äºåˆ—è¡¨æ•°æ®ï¼‰ï¼Œå¹¶é¢„åŠ è½½å…³ç³»ä»¥é¿å… N+1 --------
        t_query_build_start = time.perf_counter()
        base_query = (
            select(EventCard)
            .options(
                selectinload(EventCard.tags),
                # ç›®å‰ markets æ¥æºäº EventSnapshot.raw_dataï¼Œè¿™é‡Œæ²¡æœ‰ ORM å…³ç³»å¯é¢„åŠ è½½
                # å¦‚æœªæ¥ä¸º Market å»ºè¡¨å¹¶å»ºç«‹å…³ç³»ï¼Œå¯åœ¨æ­¤æ·»åŠ  selectinload(EventCard.markets)
            )
            .where(EventCard.is_active == True)
        )

        # æ ‡ç­¾è¿‡æ»¤
        if tagId:
            base_query = base_query.join(
                card_tags, EventCard.id == card_tags.c.card_id
            ).join(
                Tag, card_tags.c.tag_id == Tag.id
            ).where(Tag.id == int(tagId))
        t_query_build_end = time.perf_counter()
        print(f"ğŸ“‹ [Step 0] æŸ¥è¯¢æ„å»ºè€—æ—¶: {(t_query_build_end - t_query_build_start) * 1000:.2f}ms")

        # -------- 2. ä¼˜åŒ– Count æŸ¥è¯¢ï¼šç›´æ¥è®¡æ•°ï¼Œé¿å…å­æŸ¥è¯¢å’Œæ’åº --------
        t_count_start = time.perf_counter()
        # æ„å»ºå¹²å‡€çš„ count æŸ¥è¯¢ï¼Œå®Œå…¨ä¸ä¾èµ– base_queryï¼Œé¿å…ä»»ä½•å­æŸ¥è¯¢å¼€é”€
        if tagId:
            # æ ‡ç­¾è¿‡æ»¤ï¼šä½¿ç”¨ COUNT(DISTINCT) é¿å… JOIN å¯¼è‡´çš„é‡å¤è®¡æ•°
            count_query = (
                select(func.count(func.distinct(EventCard.id)))
                .select_from(EventCard)
                .join(card_tags, EventCard.id == card_tags.c.card_id)
                .join(Tag, card_tags.c.tag_id == Tag.id)
                .where(EventCard.is_active == True)
                .where(Tag.id == int(tagId))
            )
        else:
            # æ— è¿‡æ»¤ï¼šç›´æ¥è®¡æ•°ï¼Œæœ€ç®€å•æœ€å¿«
            count_query = (
                select(func.count(EventCard.id))
                .where(EventCard.is_active == True)
            )
        
        # ç›´æ¥æ‰§è¡Œ count æŸ¥è¯¢
        total_result = await db.execute(count_query)
        total_count = total_result.scalar_one() or 0
        t_count_end = time.perf_counter()
        print(f"ğŸ“Š [Step 1] Count æŸ¥è¯¢è€—æ—¶: {(t_count_end - t_count_start) * 1000:.2f}ms (Total: {total_count})")

        # -------- 3. æ’åºï¼ˆä»åœ¨ SQL å±‚é¢ï¼‰ --------
        query = base_query
        # æ³¨æ„ï¼šliquidity å­˜å‚¨åœ¨ raw_data ä¸­ï¼Œæ— æ³•ç›´æ¥åœ¨ SQL å±‚é¢æ’åº
        # å¦‚æœæŒ‰ liquidity æ’åºï¼Œéœ€è¦åœ¨ Python å±‚é¢å¤„ç†
        if sortBy == "volume":
            sort_column = EventCard.volume
            if order == "desc":
                query = query.order_by(desc(sort_column))
            else:
                query = query.order_by(sort_column)
        else:  # liquidity - éœ€è¦åœ¨è·å–æ•°æ®åæ’åº
            # å…ˆæŒ‰ volume æ’åºä½œä¸ºé»˜è®¤ï¼Œç„¶ååœ¨ Python å±‚é¢é‡æ–°æ’åº
            query = query.order_by(desc(EventCard.volume))

        # -------- 4. åˆ†é¡µ --------
        offset = (page - 1) * pageSize
        query = query.offset(offset).limit(pageSize)

        # -------- 5. è¯Šæ–­ Main Query (DB + ç½‘ç»œ) è€—æ—¶ --------
        t_query_start = time.perf_counter()
        result = await db.execute(query)
        cards = result.scalars().all()
        t_query_end = time.perf_counter()
        print(f"ğŸ¢ [Step 2] åˆ—è¡¨ SQL æ‰§è¡Œ + ç½‘ç»œä¼ è¾“: {(t_query_end - t_query_start) * 1000:.2f}ms (Cards: {len(cards)})")

        # -------- 6. ä¼˜åŒ– Snapshot æŸ¥è¯¢ï¼šä½¿ç”¨çª—å£å‡½æ•°è·å–æœ€æ–°å¿«ç…§ --------
        t_snap_start = time.perf_counter()
        card_data_list = []
        if cards:
            polymarket_ids = [card.polymarket_id for card in cards]

            # ä½¿ç”¨çª—å£å‡½æ•°å­æŸ¥è¯¢ï¼šä¸ºæ¯ä¸ª polymarket_id æ‰¾åˆ°æœ€æ–°çš„ created_at
            # ç„¶å JOIN å›åŸè¡¨è·å–å®Œæ•´è®°å½•ï¼ˆæ¯”å¾ªç¯è¿‡æ»¤å¿«å¾—å¤šï¼‰
            from sqlalchemy import text
            # ä½¿ç”¨ PostgreSQL çš„ DISTINCT ONï¼ˆæ€§èƒ½æœ€ä¼˜ï¼Œä½†éœ€è¦åŸç”Ÿ SQLï¼‰
            snapshots_query = text("""
                SELECT DISTINCT ON (polymarket_id) 
                    id, polymarket_id, raw_data, created_at
                FROM event_snapshots
                WHERE polymarket_id = ANY(:ids)
                ORDER BY polymarket_id, created_at DESC
            """)
            
            snapshots_result = await db.execute(
                snapshots_query, {"ids": polymarket_ids}
            )
            snapshots_rows = snapshots_result.mappings().all()

            # å°†ç»“æœæ˜ å°„å›å­—å…¸æ ¼å¼ï¼ˆç›´æ¥ä½¿ç”¨ raw_dataï¼Œæ— éœ€åˆ›å»º EventSnapshot å¯¹è±¡ï¼‰
            latest_snapshot_by_id: dict[str, dict] = {}
            for row in snapshots_rows:
                latest_snapshot_by_id[row["polymarket_id"]] = {
                    "raw_data": row["raw_data"],
                    "created_at": row["created_at"],
                }

            # æ„å»ºå¡ç‰‡æ•°æ®
            t_build_start = time.perf_counter()
            for card in cards:
                snapshot_data = latest_snapshot_by_id.get(card.polymarket_id)
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ EventSnapshot å¯¹è±¡ç”¨äº _build_card_data
                snapshot = None
                if snapshot_data:
                    snapshot = EventSnapshot(
                        polymarket_id=card.polymarket_id,
                        raw_data=snapshot_data["raw_data"],
                        created_at=snapshot_data["created_at"],
                    )
                card_dict = _build_card_data(card, snapshot)
                card_data_list.append(card_dict)
            t_build_end = time.perf_counter()
            print(f"ğŸ”„ [Step 3] Snapshot æ‰¹é‡æŸ¥è¯¢: {(t_build_start - t_snap_start) * 1000:.2f}ms")
            print(f"   ğŸ“¦ [Step 3.1] æ•°æ®æ„å»ºè€—æ—¶: {(t_build_end - t_build_start) * 1000:.2f}ms")
        t_snap_end = time.perf_counter()
        print(f"ğŸ”„ [Step 3 Total] Snapshot å¤„ç†æ€»è€—æ—¶: {(t_snap_end - t_snap_start) * 1000:.2f}ms")

        # -------- 7. å¦‚æœæŒ‰ liquidity æ’åºï¼Œåœ¨ Python å±‚é¢æ’åº --------
        if sortBy == "liquidity":
            t_sort_start = time.perf_counter()
            card_data_list.sort(
                key=lambda x: x.get("liquidity") or 0,
                reverse=(order == "desc"),
            )
            t_sort_end = time.perf_counter()
            print(f"ğŸ”€ [Step 4] Python å±‚é¢æ’åºè€—æ—¶: {(t_sort_end - t_sort_start) * 1000:.2f}ms")

        # -------- 8. è¯Šæ–­ Pydantic åºåˆ—åŒ–è€—æ—¶ --------
        t_serialize_start = time.perf_counter()
        card_data_objects = [CardData(**item) for item in card_data_list]
        t_serialize_end = time.perf_counter()
        print(f"ğŸ§  [Step 5] Pydantic åºåˆ—åŒ– (CPU): {(t_serialize_end - t_serialize_start) * 1000:.2f}ms")

        # æ„å»ºç¬¦åˆå‰ç«¯æœŸæœ›ç»“æ„çš„åˆ†é¡µè½½ä½“
        payload = CardListPayload(
            total=total_count,
            page=page,
            pageSize=pageSize,
            list=card_data_objects,
        )

        overall_end = time.perf_counter()
        print(f"ğŸ [Total] æ€»æ¥å£é€»è¾‘è€—æ—¶: {(overall_end - overall_start) * 1000:.2f}ms")
        print("=" * 60 + "\n")

        return CardListResponse(
            code=200,
            message="success",
            data=payload,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/details", response_model=CardDetailsResponse)
@profile_endpoint
async def get_card_details(
    id: str = Query(..., description="Polymarket Event ID"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡è¯¦æƒ…
    
    - **id**: Polymarket Event IDï¼ˆå¯¹åº” EventCard.polymarket_idï¼‰
    """
    try:
        # æŸ¥è¯¢ EventCard
        card_query = select(EventCard).where(EventCard.polymarket_id == id)
        card_result = await db.execute(card_query)
        card = card_result.scalar_one_or_none()

        if not card:
            raise HTTPException(status_code=404, detail=f"Card with id '{id}' not found")

        # è·å–æœ€æ–°çš„ EventSnapshot
        snapshot_query = (
            select(EventSnapshot)
            .where(EventSnapshot.polymarket_id == id)
            .order_by(desc(EventSnapshot.created_at))
            .limit(1)
        )
        snapshot_result = await db.execute(snapshot_query)
        snapshot = snapshot_result.scalar_one_or_none()

        card_dict = _build_card_data(card, snapshot)

        return CardDetailsResponse(
            code=200,
            message="success",
            data=CardData(**card_dict),
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")




================================================================================
FILE: app/api/endpoints/__init__.py
================================================================================

"""API ç«¯ç‚¹æ¨¡å—"""


================================================================================
FILE: app/services/crawler.py
================================================================================

import asyncio
import httpx
import time
import random
from datetime import datetime
from typing import List, Dict, Any

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.dialects.postgresql import insert

from app.db.session import async_session_factory
from app.models import EventSnapshot, EventCard, Tag, CardTag

# --- é…ç½®åŒºåŸŸ ---
POLYMARKET_API_URL = "https://gamma-api.polymarket.com/events"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
# âš ï¸ å¦‚æœä½ çš„ä»£ç†ç«¯å£ä¸æ˜¯ 7890ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹
PROXY_URL = "http://127.0.0.1:7890" 

class PolymarketCrawler:
    def __init__(self):
        # é…ç½®ä»£ç†å’Œè¶…æ—¶
        self.client = httpx.AsyncClient(
            timeout=30.0, 
            headers=HEADERS,
            # proxies={
            #     "http://": PROXY_URL,
            #     "https://": PROXY_URL,
            # }
        )

    async def fetch_page(self, limit: int = 50, offset: int = 0):
        """æŠ“å–å•é¡µæ•°æ® (å¸¦è®¡æ—¶)"""
        params = {
            "active": "true",
            "closed": "false",
            "limit": limit,
            "offset": offset,
            "order": "volume",
            "ascending": "false",
        }

        try:
            print(f"ğŸ•·ï¸ [Offset {offset}] å‡†å¤‡å‘èµ·è¯·æ±‚...")
            
            # â±ï¸ è®¡æ—¶ç‚¹ 1: API è¯·æ±‚
            t_start = time.time()
            response = await self.client.get(POLYMARKET_API_URL, params=params)
            t_net = time.time()
            
            # æ‰“å° API è€—æ—¶
            duration = t_net - t_start
            print(f"   ğŸ“¡ [ç½‘ç»œ] Polymarket API è€—æ—¶: {duration:.2f}s")
            
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ [Offset {offset}] æŠ“å–å¤±è´¥: {str(e)}")
            return []

    async def save_batch(self, events_data: List[Dict[str, Any]]):
        """åˆ†æ‰¹å­˜å…¥æ•°æ®åº“ (ä¿®å¤æ­»é”ç‰ˆï¼šæ‰¹é‡å¤„ç† Tags)"""
        if not events_data:
            return

        t_start = time.time()

        async with async_session_factory() as session:
            try:
                # =================================================
                # ç¬¬ä¸€æ­¥ï¼šæå–æ‰€æœ‰ Tags å¹¶æ‰¹é‡å¤„ç† (è§£å†³æ­»é”æ ¸å¿ƒ)
                # =================================================
                # 1. æ”¶é›†æœ¬æ‰¹æ¬¡æ‰€æœ‰ç”¨åˆ°çš„ tag slug
                all_tag_slugs = set()
                for event in events_data:
                    for t in event.get("tags", []):
                        if t.get("slug"):
                            all_tag_slugs.add(t.get("slug"))
                
                # 2. æ’åº (å…³é”®ï¼é˜²æ­¢æ­»é”)
                sorted_slugs = sorted(list(all_tag_slugs))

                tag_map = {}  # å­˜æ”¾ name -> id çš„æ˜ å°„

                if sorted_slugs:
                    # 3. æ‰¹é‡æ’å…¥ Tags (ON CONFLICT DO NOTHING)
                    # æˆ‘ä»¬ä¸éœ€è¦åœ¨è¿™é‡Œ RETURNING idï¼Œå› ä¸ºå¯èƒ½æœ‰çš„å·²ç»å­˜åœ¨äº†ï¼ŒRETURNING ä¼šæ‹¿ä¸åˆ°
                    await session.execute(
                        insert(Tag)
                        .values([{"name": slug} for slug in sorted_slugs])
                        .on_conflict_do_nothing(index_elements=["name"])
                    )

                    # 4. æ‰¹é‡æŸ¥å‡ºæ‰€æœ‰ Tags çš„ ID
                    tag_stmt = select(Tag.name, Tag.id).where(Tag.name.in_(sorted_slugs))
                    tag_results = await session.execute(tag_stmt)
                    for name, tag_id in tag_results.all():
                        tag_map[name] = tag_id

                # =================================================
                # ç¬¬äºŒæ­¥ï¼šå¤„ç† EventCard å’Œ å…³è”å…³ç³»
                # =================================================
                for event in events_data:
                    poly_id = str(event.get("id"))
                    
                    # å­—æ®µæ¸…æ´—
                    image_url = event.get("image") or event.get("icon")
                    try:
                        volume = float(event.get("volume") or 0)
                    except:
                        volume = 0.0
                    
                    end_date = None
                    if event.get("endDate"):
                        try:
                            end_date = datetime.fromisoformat(event.get("endDate").replace("Z", "+00:00"))
                        except:
                            pass

                    # æ·»åŠ å¿«ç…§
                    session.add(EventSnapshot(polymarket_id=poly_id, raw_data=event))

                    # Upsert EventCard
                    stmt = (
                        insert(EventCard)
                        .values(
                            polymarket_id=poly_id,
                            title=event.get("title", "No Title"),
                            slug=event.get("slug", poly_id),
                            description=event.get("description"),
                            image_url=image_url,
                            volume=volume,
                            end_date=end_date,
                            is_active=event.get("active", True),
                            updated_at=datetime.utcnow(),
                        )
                        .on_conflict_do_update(
                            index_elements=["polymarket_id"],
                            set_={
                                "title": event.get("title"),
                                "volume": volume,
                                "updated_at": datetime.utcnow(),
                                "image_url": image_url,
                                "is_active": event.get("active", True)
                            },
                        )
                    )
                    
                    # è·å– Card ID
                    result = await session.execute(stmt.returning(EventCard.id))
                    card_id = result.scalar_one()

                    # å»ºç«‹å…³è” (ä½¿ç”¨å†…å­˜é‡Œçš„ tag_mapï¼Œä¸å†æŸ¥åº“)
                    raw_tags = event.get("tags", [])
                    for tag_data in raw_tags:
                        t_slug = tag_data.get("slug")
                        if t_slug and t_slug in tag_map:
                            t_id = tag_map[t_slug]
                            
                            # æ’å…¥å…³è” (å¿½ç•¥å†²çª)
                            # ä½¿ç”¨ insert è€Œä¸æ˜¯ add å¯¹è±¡ï¼Œç¨å¾®å¿«ä¸€ç‚¹
                            link_stmt = (
                                insert(CardTag)
                                .values(card_id=card_id, tag_id=t_id)
                                .on_conflict_do_nothing()
                            )
                            await session.execute(link_stmt)

                # æäº¤äº‹åŠ¡
                await session.commit()
                t_commit = time.time()
                
                # ç®—ä¸€ä¸‹è¿™ä¸€æ‰¹çš„å¹³å‡è€—æ—¶
                total_time = t_commit - t_start
                print(f"   ğŸ’¾ [æ•°æ®åº“] å†™å…¥ {len(events_data)} æ¡ | è€—æ—¶: {total_time:.2f}s")

            except Exception as e:
                await session.rollback()
                # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯å †æ ˆï¼Œæ–¹ä¾¿è°ƒè¯•
                print(f"âŒ å…¥åº“æ‰¹æ¬¡å¤±è´¥: {str(e)}")

    async def close(self):
        await self.client.aclose()


# -------------------------------------------------
# ğŸš€ æé€Ÿå¹¶å‘æ‰§è¡Œå…¥å£
# -------------------------------------------------
async def process_batch_task(crawler, offset, semaphore):
    """å•ä¸ªæ‰¹æ¬¡ä»»åŠ¡"""
    async with semaphore:
        data = await crawler.fetch_page(limit=50, offset=offset)
        
        # ğŸ‘‡ åŠ è¿™è¡Œæ—¥å¿—
        print(f"ğŸ“„ Offset {offset}: æŠ“åˆ° {len(data)} æ¡æ•°æ®")
        
        if not data:
            return 0
        await crawler.save_batch(data)
        return len(data)

async def run_batch_crawl():
    crawler = PolymarketCrawler()
    
    # --- å‚æ•°é…ç½® ---
    TOTAL_TARGET = 1000   # ç›®æ ‡æŠ“å–æ•°é‡
    BATCH_SIZE = 50       # æ¯é¡µæ•°é‡
    CONCURRENCY = 5       # ğŸ”¥ å¹¶å‘æ•°ï¼šåŒæ—¶å‘ 5 ä¸ªè¯·æ±‚
    
    print(f"ğŸš€ å¯åŠ¨æé€Ÿçˆ¬è™« | ç›®æ ‡: {TOTAL_TARGET} | å¹¶å‘: {CONCURRENCY}")
    
    semaphore = asyncio.Semaphore(CONCURRENCY)
    offsets = range(0, TOTAL_TARGET, BATCH_SIZE)
    
    tasks = []
    for offset in offsets:
        task = process_batch_task(crawler, offset, semaphore)
        tasks.append(task)
    
    try:
        t_start = time.time()
        results = await asyncio.gather(*tasks)
        t_end = time.time()
        
        total = sum(results)
        print("-" * 40)
        print(f"ğŸ‰ ä»»åŠ¡ç»“æŸï¼å…±å¤„ç† {total} æ¡æ•°æ®")
        print(f"â±ï¸ æ€»è€—æ—¶: {t_end - t_start:.2f}s")
        print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {total / (t_end - t_start):.2f} æ¡/ç§’")
            
    finally:
        await crawler.close()

if __name__ == "__main__":
    asyncio.run(run_batch_crawl())