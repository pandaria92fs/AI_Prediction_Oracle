"""
å®Œæ•´æµç¨‹è„šæœ¬ï¼šçˆ¬å–æ•°æ® â†’ AI åˆ†æ â†’ å­˜å‚¨é¢„æµ‹

Usage:
    python -m scripts.crawl_and_analyze [--limit N] [--skip-ai]

æµç¨‹ï¼š
    1. çˆ¬å– Polymarket æ•°æ®
    2. å­˜å‚¨ EventCard å’Œ EventSnapshot
    3. è°ƒç”¨ Gemini AI åˆ†ææ¯ä¸ªäº‹ä»¶
    4. å­˜å‚¨ AIPrediction åˆ°æ•°æ®åº“
"""

import asyncio
import sys
import os
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from dotenv import load_dotenv
load_dotenv()

from sqlalchemy import select, delete
from sqlalchemy.dialects.postgresql import insert

from app.db.session import async_session_factory
from app.models import EventCard, EventSnapshot, Tag, CardTag, AIPrediction
from app.services.crawler import PolymarketCrawler
from app.services.gemini_analyzer import ai_analyzer


async def crawl_and_save(crawler: PolymarketCrawler, limit: int = 10) -> list:
    """
    çˆ¬å–æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    
    Returns:
        ä¿å­˜æˆåŠŸçš„ event æ•°æ®åˆ—è¡¨
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“¡ Step 1: çˆ¬å– Polymarket æ•°æ® (limit: {limit})")
    print(f"{'='*60}")
    
    # çˆ¬å–æ•°æ®
    events_data = await crawler.fetch_page(limit=limit, offset=0)
    
    if not events_data:
        print("âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®")
        return []
    
    print(f"âœ… è·å–åˆ° {len(events_data)} æ¡äº‹ä»¶æ•°æ®")
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    await crawler.save_batch(events_data)
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
    
    return events_data


async def analyze_and_save(events_data: list):
    """
    å¯¹äº‹ä»¶è¿›è¡Œ AI åˆ†æå¹¶ä¿å­˜é¢„æµ‹ç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"ğŸ¤– Step 2: AI åˆ†æ ({len(events_data)} ä¸ªäº‹ä»¶)")
    print(f"{'='*60}")
    
    if not os.getenv("GEMINI_API_KEY"):
        print("âš ï¸ GEMINI_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ AI åˆ†æ")
        return
    
    async with async_session_factory() as session:
        success_count = 0
        skip_count = 0
        error_count = 0
        
        for i, event in enumerate(events_data, 1):
            event_id = str(event.get("id", ""))
            title = event.get("title", "Unknown")[:50]
            
            print(f"\n[{i}/{len(events_data)}] åˆ†æ: {title}...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ markets
            markets = event.get("markets", [])
            if not markets:
                print(f"   âš ï¸ è·³è¿‡ (æ—  markets)")
                skip_count += 1
                continue
            
            # æ„å»ºäº‹ä»¶æ•°æ®ç”¨äº AI åˆ†æ
            event_data = {
                "title": event.get("title", ""),
                "description": event.get("description", ""),
                "markets": markets
            }
            
            # è°ƒç”¨ AI åˆ†æ
            try:
                ai_result = await ai_analyzer.analyze_event(event_data)
            except Exception as e:
                print(f"   âŒ AI åˆ†æå¤±è´¥: {e}")
                error_count += 1
                continue
            
            if not ai_result:
                print(f"   âŒ AI è¿”å›ç©ºç»“æœ")
                error_count += 1
                continue
            
            # è§£æç»“æœ
            summary = ai_result.get("executive_summary", "No summary available")
            markets_data = ai_result.get("markets", {})
            
            print(f"   ğŸ“ Summary: {summary[:60]}...")
            print(f"   ğŸ“ˆ åˆ†æäº† {len(markets_data)} ä¸ª markets")
            
            # æ‰¾åˆ°æœ€é«˜ confidence çš„ market ä½œä¸ºä¸»è¦é¢„æµ‹
            primary_prediction = "0"
            primary_conf = 0.0
            
            for mid, mdata in markets_data.items():
                conf = mdata.get("confidence_score", 0)
                if conf > primary_conf:
                    primary_conf = conf
                    odds = mdata.get("ai_calibrated_odds", 0) * 100
                    primary_prediction = f"{odds:.1f}"
            
            # è½¬æ¢ä¸ºå­˜å‚¨æ ¼å¼
            raw_analysis = ai_analyzer.transform_to_raw_analysis(ai_result)
            
            # è¡¥å……åŸå§‹æ•°æ®
            for market in markets:
                market_id = str(market.get("id", ""))
                if market_id in raw_analysis:
                    raw_analysis[market_id]["question"] = market.get("question", "")
                    outcome_prices = market.get("outcomePrices", [])
                    if outcome_prices:
                        try:
                            if isinstance(outcome_prices, str):
                                outcome_prices = json.loads(outcome_prices)
                            raw_analysis[market_id]["original_odds"] = float(outcome_prices[0])
                        except (json.JSONDecodeError, ValueError, IndexError):
                            pass
            
            # æŸ¥æ‰¾ card_id
            card_stmt = select(EventCard.id).where(EventCard.polymarket_id == event_id)
            card_result = await session.execute(card_stmt)
            card_row = card_result.first()
            
            if not card_row:
                print(f"   âš ï¸ æœªæ‰¾åˆ°å¯¹åº”çš„ EventCard")
                skip_count += 1
                continue
            
            card_id = card_row[0]
            
            # åˆ é™¤æ—§çš„é¢„æµ‹
            await session.execute(
                delete(AIPrediction).where(AIPrediction.card_id == card_id)
            )
            
            # å­˜å…¥ AIPrediction è¡¨
            new_prediction = AIPrediction(
                card_id=card_id,
                summary=summary,
                outcome_prediction=primary_prediction,
                confidence_score=min(primary_conf * 10, 99.99),
                raw_analysis=json.dumps(raw_analysis, ensure_ascii=False)
            )
            
            session.add(new_prediction)
            success_count += 1
            print(f"   âœ… å·²ä¿å­˜ AI é¢„æµ‹")
        
        await session.commit()
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š AI åˆ†æå®Œæˆç»Ÿè®¡:")
        print(f"   âœ… æˆåŠŸ: {success_count}")
        print(f"   âš ï¸ è·³è¿‡: {skip_count}")
        print(f"   âŒ å¤±è´¥: {error_count}")
        print(f"{'='*60}")


async def main():
    # è§£æå‚æ•°
    limit = 10
    skip_ai = False
    
    args = sys.argv[1:]
    i = 0
    while i < len(args):
        if args[i] == "--limit" and i + 1 < len(args):
            try:
                limit = int(args[i + 1])
            except ValueError:
                pass
            i += 2
        elif args[i] == "--skip-ai":
            skip_ai = True
            i += 1
        else:
            try:
                limit = int(args[i])
            except ValueError:
                pass
            i += 1
    
    print(f"\nğŸš€ å¯åŠ¨å®Œæ•´æµç¨‹ (limit: {limit}, skip_ai: {skip_ai})")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    crawler = PolymarketCrawler()
    
    try:
        # Step 1: çˆ¬å–å¹¶ä¿å­˜
        events_data = await crawl_and_save(crawler, limit)
        
        if not events_data:
            return
        
        # Step 2: AI åˆ†æå¹¶ä¿å­˜
        if not skip_ai:
            await analyze_and_save(events_data)
        else:
            print("\nâ­ï¸ è·³è¿‡ AI åˆ†æ (--skip-ai)")
        
        print(f"\nğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆ!")
        
    finally:
        await crawler.close()


if __name__ == "__main__":
    asyncio.run(main())
