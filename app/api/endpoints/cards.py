"""Card API ç«¯ç‚¹"""
import time
from typing import Optional

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import desc, func, select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.decorators import profile_endpoint
from app.db.session import get_db
from app.models.ai_prediction import AIPrediction
from app.models.card_tag import card_tags
from app.models.event_card import EventCard
from app.models.event_snapshot import EventSnapshot
from app.models.tag import Tag
from app.schemas.card import (
    CardData,
    CardDetailsResponse,
    CardListPayload,
    CardListResponse,
)

router = APIRouter()


def _extract_markets_from_raw_data(raw_data: dict, ai_markets: dict = None) -> list:
    """
    [æœ€ç»ˆä¿®æ­£ç‰ˆ] ä»Ž raw_data æå– markets
    1. åŒ…å« outcomePrices çš„ JSON è§£æžå…œåº•
    2. åŒ…å« AI æ•°æ®çš„å½’ä¸€åŒ–å¤„ç† (0-100 -> 0-1)
    """
    import json
    markets = raw_data.get("markets", [])
    ai_markets = ai_markets or {}
    result = []
    for market in markets:
        market_id = market.get("id", "")
        
        # --- 1. é¡½å›ºçš„æ¦‚çŽ‡èŽ·å–é€»è¾‘ ---
        probability = 0.0
        if "probability" in market:
            probability = float(market["probability"] or 0)
        
        if probability == 0.0:
            outcome_prices = market.get("outcomePrices")
            if outcome_prices:
                try:
                    if isinstance(outcome_prices, str):
                        outcome_prices = json.loads(outcome_prices)
                    if isinstance(outcome_prices, list) and len(outcome_prices) > 0:
                        probability = float(outcome_prices[0])
                except:
                    pass
        
        # --- 2. åŸºç¡€æ•°æ® ---
        market_data = {
            "id": market_id,
            "question": market.get("question", ""),
            "outcomes": market.get("outcomes", []),
            "currentPrices": market.get("currentPrices", {}),
            "volume": float(market.get("volume") or 0),
            "liquidity": float(market.get("liquidity") or 0),
            "active": market.get("active", True),
            "groupItemTitle": market.get("groupItemTitle"),
            "icon": market.get("icon"),
            "outcomePrices": market.get("outcomePrices"),
            "probability": probability,
        }
        
        # --- 3. AI æ•°æ®æ³¨å…¥ ---
        ai_adj_prob = None
        
        if "adjustedProbability" in market:
            ai_adj_prob = market["adjustedProbability"]
        elif market_id in ai_markets:
            ai_data = ai_markets[market_id]
            if "ai_calibrated_odds_pct" in ai_data:
                ai_adj_prob = ai_data["ai_calibrated_odds_pct"]
            if "ai_confidence" in ai_data:
                market_data["ai_confidence"] = float(ai_data["ai_confidence"])
            market_data["ai_analysis_data"] = {
                "structuralAnchor": ai_data.get("anchor") or ai_data.get("structural_anchor"),
                "noise": ai_data.get("noise") or ai_data.get("the_noise"),
                "barrier": ai_data.get("barrier") or ai_data.get("the_barrier"),
                "blindspot": ai_data.get("blindspot") or ai_data.get("the_blindspot"),
            }
        
        # --- 4. å½’ä¸€åŒ– 0-1 ---
        if ai_adj_prob is not None:
            val = float(ai_adj_prob)
            if val > 1.0:
                val = val / 100.0
            market_data["ai_adjusted_probability"] = val
        
        result.append(market_data)
    return result


def _extract_tags_from_raw_data(raw_data: dict) -> list:
    """ä»Ž raw_data ä¸­æå– tags åˆ—è¡¨"""
    tags = raw_data.get("tags", [])
    result = []
    for tag in tags:
        result.append({
            "id": str(tag.get("id", "")),
            "label": tag.get("label", ""),
            "slug": tag.get("slug", ""),
        })
    return result


def _build_card_data(card: EventCard, snapshot: Optional[EventSnapshot] = None, predictions: Optional[list] = None) -> dict:
    """æž„å»ºå¡ç‰‡æ•°æ®å¯¹è±¡"""
    raw_data = snapshot.raw_data if snapshot else {}
    
    # æ ¼å¼åŒ–æ—¥æœŸå­—æ®µ
    def format_date(date_value):
        """æ ¼å¼åŒ–æ—¥æœŸä¸º ISO å­—ç¬¦ä¸²"""
        if date_value is None:
            return None
        if isinstance(date_value, str):
            return date_value
        # å¦‚æžœæ˜¯ datetime å¯¹è±¡ï¼Œè½¬æ¢ä¸º ISO æ ¼å¼
        return date_value.isoformat() if hasattr(date_value, 'isoformat') else str(date_value)
    
    # èŽ·å– AI é¢„æµ‹æ•°æ®ï¼ˆä»Žæœ€æ–°çš„ prediction ä¸­æå–ï¼‰
    ai_logic_summary = None
    adjusted_probability = None
    ai_markets = {}  # market_id -> AI åˆ†æžæ•°æ®
    if predictions and len(predictions) > 0:
        # predictions åº”è¯¥æŒ‰ created_at é™åºæŽ’åºï¼Œå–ç¬¬ä¸€ä¸ª
        latest = predictions[0]
        ai_logic_summary = latest.summary
        # outcome_prediction å­˜çš„æ˜¯çº¯æ•°å­—ï¼Œå¦‚ "56.5"
        if latest.outcome_prediction:
            try:
                adjusted_probability = float(latest.outcome_prediction)
            except ValueError:
                adjusted_probability = None
        # è§£æž raw_analysis èŽ·å–æ¯ä¸ª market çš„ AI æ¦‚çŽ‡
        if latest.raw_analysis:
            try:
                import json
                ai_markets = json.loads(latest.raw_analysis)
            except (json.JSONDecodeError, TypeError):
                ai_markets = {}
    
    # åŸºç¡€å­—æ®µä»Ž EventCard èŽ·å–ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ raw_data ä¸­çš„æœ€æ–°å€¼
    # ä¿®å¤ï¼šicon å­—æ®µæ˜ å°„ - ä½¿ç”¨ validation_aliasï¼Œæ‰€ä»¥è¿™é‡Œç”¨ image_url
    card_dict = {
        "id": card.polymarket_id,  # ä½¿ç”¨ id ä½œä¸ºå…¬å¼€å­—æ®µå
        "slug": card.slug,
        "title": card.title,
        "description": card.description or raw_data.get("description"),
        "image_url": card.image_url or raw_data.get("image") or raw_data.get("icon"),  # ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ imageï¼Œå…¶æ¬¡ icon
        "volume": float(card.volume) if card.volume else (float(raw_data.get("volume", 0)) if raw_data.get("volume") else None),
        "liquidity": float(raw_data.get("liquidity", 0)) if raw_data.get("liquidity") else None,
        "active": card.is_active,
        "closed": raw_data.get("closed", False),
        "startDate": format_date(raw_data.get("startDate")),
        "endDate": format_date(raw_data.get("endDate")) or format_date(card.end_date),
        "createdAt": card.created_at.isoformat() if card.created_at else None,  # ä¿®å¤ï¼šæ·»åŠ  createdAt
        "updatedAt": card.updated_at.isoformat() if card.updated_at else None,  # ä¿®å¤ï¼šæ·»åŠ  updatedAt
        "tags": _extract_tags_from_raw_data(raw_data),
        "markets": _extract_markets_from_raw_data(raw_data, ai_markets),
        "aILogicSummary": ai_logic_summary,  # AI åˆ†æžæ‘˜è¦
        "adjustedProbability": adjusted_probability,  # AI è°ƒæ•´åŽçš„æ¦‚çŽ‡
    }
    return card_dict


@router.get("/list", response_model=CardListResponse)
@profile_endpoint
async def get_card_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    pageSize: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    tagId: Optional[str] = Query(None, description="æ ‡ç­¾ ID è¿‡æ»¤"),
    sortBy: str = Query("volume", pattern="^(volume|liquidity)$", description="æŽ’åºå­—æ®µ"),
    order: str = Query("desc", pattern="^(asc|desc)$", description="æŽ’åºæ–¹å‘"),
    db: AsyncSession = Depends(get_db),
):
    """
    èŽ·å–å¡ç‰‡åˆ—è¡¨
    
    - **page**: é¡µç ï¼ˆä»Ž 1 å¼€å§‹ï¼‰
    - **pageSize**: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - **tagId**: å¯é€‰çš„æ ‡ç­¾ ID è¿‡æ»¤
    - **sortBy**: æŽ’åºå­—æ®µï¼ˆvolume æˆ– liquidityï¼‰
    - **order**: æŽ’åºæ–¹å‘ï¼ˆasc æˆ– descï¼‰
    """
    print(f"\nâ±ï¸ === å¼€å§‹è¯¦ç»†æ€§èƒ½è¯Šæ–­ (Page: {page}, PageSize: {pageSize}) ===")
    overall_start = time.perf_counter()

    try:
        # -------- 1. æž„å»ºåŸºç¡€æŸ¥è¯¢ï¼ˆç”¨äºŽåˆ—è¡¨æ•°æ®ï¼‰ï¼Œå¹¶é¢„åŠ è½½å…³ç³»ä»¥é¿å… N+1 --------
        t_query_build_start = time.perf_counter()
        
        # ä¼˜åŒ–ï¼šä½¿ç”¨ LEFT JOIN + IS NULL ä»£æ›¿ NOT INï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
        # å­æŸ¥è¯¢ï¼šæ‰¾å‡º sports æ ‡ç­¾çš„ ID
        from sqlalchemy.orm import aliased
        sports_card_tags = aliased(card_tags, name="sports_ct")
        sports_tag_ids = select(Tag.id).where(Tag.name.ilike("%sport%")).scalar_subquery()
        
        base_query = (
            select(EventCard)
            .outerjoin(
                sports_card_tags,
                (EventCard.id == sports_card_tags.c.card_id) & 
                (sports_card_tags.c.tag_id.in_(select(Tag.id).where(Tag.name.ilike("%sport%"))))
            )
            .options(
                selectinload(EventCard.tags),
                selectinload(EventCard.predictions),
            )
            .where(EventCard.is_active == True)
            .where(EventCard.is_active.isnot(None))
            .where(EventCard.is_closed == False)
            .where(EventCard.is_closed.isnot(None))
            .where(EventCard.is_archived == False)
            .where(EventCard.is_archived.isnot(None))
            .where(sports_card_tags.c.card_id.is_(None))  # æŽ’é™¤æœ‰ sports æ ‡ç­¾çš„
        )

        # æ ‡ç­¾è¿‡æ»¤ï¼ˆä½¿ç”¨ Polymarket åŽŸå§‹ tag idï¼‰
        if tagId:
            base_query = base_query.join(
                card_tags, EventCard.id == card_tags.c.card_id
            ).join(
                Tag, card_tags.c.tag_id == Tag.id
            ).where(Tag.polymarket_id == str(tagId))
        t_query_build_end = time.perf_counter()
        print(f"ðŸ“‹ [Step 0] æŸ¥è¯¢æž„å»ºè€—æ—¶: {(t_query_build_end - t_query_build_start) * 1000:.2f}ms")

        # -------- 2. ä¼˜åŒ– Count æŸ¥è¯¢ï¼šç›´æŽ¥è®¡æ•°ï¼Œé¿å…å­æŸ¥è¯¢å’ŒæŽ’åº --------
        t_count_start = time.perf_counter()
        # æž„å»ºå¹²å‡€çš„ count æŸ¥è¯¢ï¼Œå®Œå…¨ä¸ä¾èµ– base_queryï¼Œé¿å…ä»»ä½•å­æŸ¥è¯¢å¼€é”€
        if tagId:
            # æ ‡ç­¾è¿‡æ»¤ï¼šä½¿ç”¨ COUNT(DISTINCT) é¿å… JOIN å¯¼è‡´çš„é‡å¤è®¡æ•°
            count_query = (
                select(func.count(func.distinct(EventCard.id)))
                .select_from(EventCard)
                .join(card_tags, EventCard.id == card_tags.c.card_id)
                .join(Tag, card_tags.c.tag_id == Tag.id)
                .where(EventCard.is_active == True)
                .where(Tag.polymarket_id == str(tagId))
            )
        else:
            # æ— è¿‡æ»¤ï¼šç›´æŽ¥è®¡æ•°ï¼Œæœ€ç®€å•æœ€å¿«
            count_query = (
                select(func.count(EventCard.id))
                .where(EventCard.is_active == True)
            )
        
        # ç›´æŽ¥æ‰§è¡Œ count æŸ¥è¯¢
        total_result = await db.execute(count_query)
        total_count = total_result.scalar_one() or 0
        t_count_end = time.perf_counter()
        print(f"ðŸ“Š [Step 1] Count æŸ¥è¯¢è€—æ—¶: {(t_count_end - t_count_start) * 1000:.2f}ms (Total: {total_count})")

        # -------- 3. æŽ’åºä¼˜åŒ–ï¼šå…ˆæŒ‰ volume DESC èŽ·å–å€™é€‰é›†ï¼ˆæœ€çƒ­ 100 æ¡ï¼‰ --------
        # æ··åˆæŽ’åºéœ€è¦åœ¨å€™é€‰é›†ä¸Šè¿›è¡Œï¼Œè€Œä¸æ˜¯ç›´æŽ¥åˆ†é¡µ
        CANDIDATE_POOL_SIZE = 100  # å€™é€‰æ± å¤§å°ï¼Œé¿å…å¯¹å…¨åº“é‡è®¡ç®—
        
        query = base_query.order_by(desc(EventCard.volume)).limit(CANDIDATE_POOL_SIZE)

        # -------- 5. è¯Šæ–­ Main Query (DB + ç½‘ç»œ) è€—æ—¶ --------
        t_query_start = time.perf_counter()
        result = await db.execute(query)
        cards = result.scalars().all()
        t_query_end = time.perf_counter()
        print(f"ðŸ¢ [Step 2] åˆ—è¡¨ SQL æ‰§è¡Œ + ç½‘ç»œä¼ è¾“: {(t_query_end - t_query_start) * 1000:.2f}ms (Cards: {len(cards)})")

        # -------- 6. ä¼˜åŒ– Snapshot æŸ¥è¯¢ï¼šä½¿ç”¨çª—å£å‡½æ•°èŽ·å–æœ€æ–°å¿«ç…§ --------
        t_snap_start = time.perf_counter()
        card_data_list = []
        if cards:
            polymarket_ids = [card.polymarket_id for card in cards]

            # ä½¿ç”¨çª—å£å‡½æ•°å­æŸ¥è¯¢ï¼šä¸ºæ¯ä¸ª polymarket_id æ‰¾åˆ°æœ€æ–°çš„ created_at
            # ç„¶åŽ JOIN å›žåŽŸè¡¨èŽ·å–å®Œæ•´è®°å½•ï¼ˆæ¯”å¾ªçŽ¯è¿‡æ»¤å¿«å¾—å¤šï¼‰
            from sqlalchemy import text
            # ä½¿ç”¨ PostgreSQL çš„ DISTINCT ONï¼ˆæ€§èƒ½æœ€ä¼˜ï¼Œä½†éœ€è¦åŽŸç”Ÿ SQLï¼‰
            snapshots_query = text("""
                SELECT DISTINCT ON (polymarket_id) 
                    id, polymarket_id, raw_data, created_at
                FROM event_snapshots
                WHERE polymarket_id = ANY(:ids)
                ORDER BY polymarket_id, created_at DESC
            """)
            
            snapshots_result = await db.execute(
                snapshots_query, {"ids": polymarket_ids}
            )
            snapshots_rows = snapshots_result.mappings().all()

            # å°†ç»“æžœæ˜ å°„å›žå­—å…¸æ ¼å¼ï¼ˆç›´æŽ¥ä½¿ç”¨ raw_dataï¼Œæ— éœ€åˆ›å»º EventSnapshot å¯¹è±¡ï¼‰
            latest_snapshot_by_id: dict[str, dict] = {}
            for row in snapshots_rows:
                latest_snapshot_by_id[row["polymarket_id"]] = {
                    "raw_data": row["raw_data"],
                    "created_at": row["created_at"],
                }

            # æž„å»ºå¡ç‰‡æ•°æ®
            t_build_start = time.perf_counter()
            for card in cards:
                snapshot_data = latest_snapshot_by_id.get(card.polymarket_id)
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ EventSnapshot å¯¹è±¡ç”¨äºŽ _build_card_data
                snapshot = None
                if snapshot_data:
                    snapshot = EventSnapshot(
                        polymarket_id=card.polymarket_id,
                        raw_data=snapshot_data["raw_data"],
                        created_at=snapshot_data["created_at"],
                    )
                # ä¼ å…¥ predictionsï¼ˆå·²é€šè¿‡ selectinload é¢„åŠ è½½ï¼ŒæŒ‰ created_at é™åºæŽ’åºï¼‰
                card_dict = _build_card_data(card, snapshot, card.predictions)
                card_data_list.append(card_dict)
            t_build_end = time.perf_counter()
            print(f"ðŸ”„ [Step 3] Snapshot æ‰¹é‡æŸ¥è¯¢: {(t_build_start - t_snap_start) * 1000:.2f}ms")
            print(f"   ðŸ“¦ [Step 3.1] æ•°æ®æž„å»ºè€—æ—¶: {(t_build_end - t_build_start) * 1000:.2f}ms")
        t_snap_end = time.perf_counter()
        print(f"ðŸ”„ [Step 3 Total] Snapshot å¤„ç†æ€»è€—æ—¶: {(t_snap_end - t_snap_start) * 1000:.2f}ms")

        # -------- 7. æ··åˆåŠ æƒæŽ’åºï¼švolume + AI alpha (ä¼˜åŒ–ç‰ˆ) --------
        t_sort_start = time.perf_counter()

        def _normalize_prob(val):
            """å½’ä¸€åŒ–æ¦‚çŽ‡åˆ° 0.0-1.0 èŒƒå›´"""
            if val is None:
                return 0.0
            v = float(val)
            if v > 1.0:
                v = v / 100.0
            return max(0.0, min(1.0, v))  # ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…

        def get_volume_score(card):
            return float(card.get("volume") or 0)

        def get_weighted_alpha_score(card):
            """
            è®¡ç®—åŠ æƒ alpha åˆ†æ•° = volume Ã— max_diff
            å½’ä¸€åŒ–æ‰€æœ‰æ¦‚çŽ‡åˆ° 0.0-1.0 åŽè®¡ç®—å·®å€¼
            """
            try:
                vol = float(card.get("volume") or 0)
                if vol == 0:
                    return 0
                diffs = []
                for m in card.get("markets", []):
                    # å½’ä¸€åŒ– market probability
                    prob = _normalize_prob(m.get("probability", 0.0))
                    # å½’ä¸€åŒ– AI adjusted probability
                    adj_prob = m.get("ai_adjusted_probability") or m.get("adjustedProbability")
                    if adj_prob is None:
                        curr_ai = prob  # æ—  AI æ•°æ®æ—¶ï¼Œdiff = 0
                    else:
                        curr_ai = _normalize_prob(adj_prob)
                    diff = abs(prob - curr_ai)
                    diffs.append(diff)
                # å–æœ€å¤§çš„ä¸¤ä¸ªå·®å€¼ï¼ˆå¦‚æžœæœ‰å¤šä¸ª marketï¼‰
                diffs.sort(reverse=True)
                top_diffs = diffs[:2] if len(diffs) >= 2 else diffs
                return vol * sum(top_diffs)
            except:
                return 0

        # ç”Ÿæˆä¸¤ä»½ç‹¬ç«‹æŽ’åºåˆ—è¡¨
        list_volume = sorted(card_data_list, key=get_volume_score, reverse=True)
        list_alpha = sorted(card_data_list, key=get_weighted_alpha_score, reverse=True)

        # è°ƒè¯•ï¼šæ‰“å°å‰ 5 åçš„æŽ’åºæƒ…å†µ
        print(f"   ðŸ“Š Volume Top5: {[c.get('id')[:8] + '...' for c in list_volume[:5]]}")
        print(f"   ðŸ“Š Alpha Top5:  {[c.get('id')[:8] + '...' for c in list_alpha[:5]]}")

        # ç²¾ç¡®äº¤æ›¿æ’å€¼ï¼šIndex 0 -> volume[0], Index 1 -> alpha[0], Index 2 -> volume[1], ...
        final_list = []
        used_ids = set()
        ptr_vol, ptr_alpha = 0, 0
        turn_volume = True  # ä»Ž volume å¼€å§‹

        while len(final_list) < len(card_data_list):
            if turn_volume:
                # ä»Ž list_volume å–ä¸‹ä¸€ä¸ªæœªä½¿ç”¨çš„
                while ptr_vol < len(list_volume):
                    card = list_volume[ptr_vol]
                    ptr_vol += 1
                    if card.get("id") not in used_ids:
                        final_list.append(card)
                        used_ids.add(card.get("id"))
                        break
                else:
                    # list_volume å·²è€—å°½ï¼Œåˆ‡æ¢åˆ° alpha
                    turn_volume = False
                    continue
            else:
                # ä»Ž list_alpha å–ä¸‹ä¸€ä¸ªæœªä½¿ç”¨çš„ï¼ˆåŽ»é‡ä¿æŠ¤ï¼šè‡ªåŠ¨é¡ºå»¶ï¼‰
                while ptr_alpha < len(list_alpha):
                    card = list_alpha[ptr_alpha]
                    ptr_alpha += 1
                    if card.get("id") not in used_ids:
                        final_list.append(card)
                        used_ids.add(card.get("id"))
                        break
                else:
                    # list_alpha å·²è€—å°½ï¼Œåˆ‡æ¢åˆ° volume
                    turn_volume = True
                    continue
            # äº¤æ›¿åˆ‡æ¢
            turn_volume = not turn_volume

        # -------- 8. åº”ç”¨åˆ†é¡µï¼ˆåœ¨æ··åˆæŽ’åºåŽï¼‰ --------
        offset = (page - 1) * pageSize
        card_data_list = final_list[offset:offset + pageSize]
        
        t_sort_end = time.perf_counter()
        print(f"ðŸ”€ [Step 4] æ··åˆåŠ æƒæŽ’åºå®Œæˆ: {(t_sort_end - t_sort_start) * 1000:.2f}ms (å€™é€‰æ± : {len(final_list)}, è¿”å›ž: {len(card_data_list)})")
        
        # è°ƒè¯•ï¼šæ‰“å°å½“å‰é¡µçš„äº¤æ›¿æƒ…å†µï¼ˆå‰ 10 æ¡ï¼‰
        debug_slice = final_list[offset:offset + min(10, pageSize)]
        for i, c in enumerate(debug_slice):
            src = "VOL" if i % 2 == 0 else "ALP"
            print(f"   [{offset + i}] {src}: {c.get('id')[:12]}... vol={c.get('volume', 0):.0f}")

        # -------- 9. è¯Šæ–­ Pydantic åºåˆ—åŒ–è€—æ—¶ --------
        t_serialize_start = time.perf_counter()
        card_data_objects = [CardData(**item) for item in card_data_list]
        t_serialize_end = time.perf_counter()
        print(f"ðŸ§  [Step 5] Pydantic åºåˆ—åŒ– (CPU): {(t_serialize_end - t_serialize_start) * 1000:.2f}ms")

        # æž„å»ºç¬¦åˆå‰ç«¯æœŸæœ›ç»“æž„çš„åˆ†é¡µè½½ä½“
        payload = CardListPayload(
            total=total_count,
            page=page,
            pageSize=pageSize,
            list=card_data_objects,
        )

        overall_end = time.perf_counter()
        print(f"ðŸ [Total] æ€»æŽ¥å£é€»è¾‘è€—æ—¶: {(overall_end - overall_start) * 1000:.2f}ms")
        print("=" * 60 + "\n")

        return CardListResponse(
            code=200,
            message="success",
            data=payload,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/details", response_model=CardDetailsResponse)
@profile_endpoint
async def get_card_details(
    id: str = Query(..., description="Polymarket Event ID"),
    db: AsyncSession = Depends(get_db),
):
    """
    èŽ·å–å¡ç‰‡è¯¦æƒ…
    
    - **id**: Polymarket Event IDï¼ˆå¯¹åº” EventCard.polymarket_idï¼‰
    """
    try:
        # æŸ¥è¯¢ EventCardï¼Œé¢„åŠ è½½ predictions
        card_query = (
            select(EventCard)
            .options(selectinload(EventCard.predictions))
            .where(EventCard.polymarket_id == id)
        )
        card_result = await db.execute(card_query)
        card = card_result.scalar_one_or_none()

        if not card:
            raise HTTPException(status_code=404, detail=f"Card with id '{id}' not found")

        # èŽ·å–æœ€æ–°çš„ EventSnapshot
        snapshot_query = (
            select(EventSnapshot)
            .where(EventSnapshot.polymarket_id == id)
            .order_by(desc(EventSnapshot.created_at))
            .limit(1)
        )
        snapshot_result = await db.execute(snapshot_query)
        snapshot = snapshot_result.scalar_one_or_none()

        card_dict = _build_card_data(card, snapshot, card.predictions)

        return CardDetailsResponse(
            code=200,
            message="success",
            data=CardData(**card_dict),
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


