"""Card API ç«¯ç‚¹"""
import time
from typing import Optional

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import desc, func, select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.decorators import profile_endpoint
from app.db.session import get_db
from app.models.ai_prediction import AIPrediction
from app.models.card_tag import card_tags
from app.models.event_card import EventCard
from app.models.event_snapshot import EventSnapshot
from app.models.tag import Tag
from app.schemas.card import (
    CardData,
    CardDetailsResponse,
    CardListPayload,
    CardListResponse,
)

router = APIRouter()


def _extract_markets_from_raw_data(raw_data: dict, ai_markets: dict = None) -> list:
    """
    [æœ€ç»ˆä¿®æ­£ç‰ˆ] ä» raw_data æå– markets
    1. åŒ…å« outcomePrices çš„ JSON è§£æå…œåº•
    2. åŒ…å« AI æ•°æ®çš„å½’ä¸€åŒ–å¤„ç† (0-100 -> 0-1)
    """
    import json
    markets = raw_data.get("markets", [])
    ai_markets = ai_markets or {}
    result = []
    for market in markets:
        market_id = market.get("id", "")
        
        # --- 1. é¡½å›ºçš„æ¦‚ç‡è·å–é€»è¾‘ ---
        probability = 0.0
        if "probability" in market:
            probability = float(market["probability"] or 0)
        
        if probability == 0.0:
            outcome_prices = market.get("outcomePrices")
            if outcome_prices:
                try:
                    if isinstance(outcome_prices, str):
                        outcome_prices = json.loads(outcome_prices)
                    if isinstance(outcome_prices, list) and len(outcome_prices) > 0:
                        probability = float(outcome_prices[0])
                except:
                    pass
        
        # --- 2. åŸºç¡€æ•°æ® ---
        market_data = {
            "id": market_id,
            "question": market.get("question", ""),
            "outcomes": market.get("outcomes", []),
            "currentPrices": market.get("currentPrices", {}),
            "volume": float(market.get("volume") or 0),
            "liquidity": float(market.get("liquidity") or 0),
            "active": market.get("active", True),
            "groupItemTitle": market.get("groupItemTitle"),
            "icon": market.get("icon"),
            "outcomePrices": market.get("outcomePrices"),
            "probability": probability,
        }
        
        # --- 3. AI æ•°æ®æ³¨å…¥ ---
        ai_adj_prob = None
        
        if "adjustedProbability" in market:
            ai_adj_prob = market["adjustedProbability"]
        elif market_id in ai_markets:
            ai_data = ai_markets[market_id]
            if "ai_calibrated_odds_pct" in ai_data:
                ai_adj_prob = ai_data["ai_calibrated_odds_pct"]
            if "ai_confidence" in ai_data:
                market_data["ai_confidence"] = float(ai_data["ai_confidence"])
            market_data["ai_analysis_data"] = {
                "structuralAnchor": ai_data.get("anchor") or ai_data.get("structural_anchor"),
                "noise": ai_data.get("noise") or ai_data.get("the_noise"),
                "barrier": ai_data.get("barrier") or ai_data.get("the_barrier"),
                "blindspot": ai_data.get("blindspot") or ai_data.get("the_blindspot"),
            }
        
        # --- 4. å½’ä¸€åŒ– 0-1 ---
        if ai_adj_prob is not None:
            val = float(ai_adj_prob)
            if val > 1.0:
                val = val / 100.0
            market_data["ai_adjusted_probability"] = val
        
        result.append(market_data)
    return result


def _extract_tags_from_raw_data(raw_data: dict) -> list:
    """ä» raw_data ä¸­æå– tags åˆ—è¡¨"""
    tags = raw_data.get("tags", [])
    result = []
    for tag in tags:
        result.append({
            "id": str(tag.get("id", "")),
            "label": tag.get("label", ""),
            "slug": tag.get("slug", ""),
        })
    return result


def _build_card_data(card: EventCard, snapshot: Optional[EventSnapshot] = None, predictions: Optional[list] = None) -> dict:
    """æ„å»ºå¡ç‰‡æ•°æ®å¯¹è±¡"""
    raw_data = snapshot.raw_data if snapshot else {}
    
    # æ ¼å¼åŒ–æ—¥æœŸå­—æ®µ
    def format_date(date_value):
        """æ ¼å¼åŒ–æ—¥æœŸä¸º ISO å­—ç¬¦ä¸²"""
        if date_value is None:
            return None
        if isinstance(date_value, str):
            return date_value
        # å¦‚æœæ˜¯ datetime å¯¹è±¡ï¼Œè½¬æ¢ä¸º ISO æ ¼å¼
        return date_value.isoformat() if hasattr(date_value, 'isoformat') else str(date_value)
    
    # è·å– AI é¢„æµ‹æ•°æ®ï¼ˆä»æœ€æ–°çš„ prediction ä¸­æå–ï¼‰
    ai_logic_summary = None
    adjusted_probability = None
    ai_markets = {}  # market_id -> AI åˆ†ææ•°æ®
    if predictions and len(predictions) > 0:
        # predictions åº”è¯¥æŒ‰ created_at é™åºæ’åºï¼Œå–ç¬¬ä¸€ä¸ª
        latest = predictions[0]
        ai_logic_summary = latest.summary
        # outcome_prediction å­˜çš„æ˜¯çº¯æ•°å­—ï¼Œå¦‚ "56.5"
        if latest.outcome_prediction:
            try:
                adjusted_probability = float(latest.outcome_prediction)
            except ValueError:
                adjusted_probability = None
        # è§£æ raw_analysis è·å–æ¯ä¸ª market çš„ AI æ¦‚ç‡
        if latest.raw_analysis:
            try:
                import json
                ai_markets = json.loads(latest.raw_analysis)
            except (json.JSONDecodeError, TypeError):
                ai_markets = {}
    
    # åŸºç¡€å­—æ®µä» EventCard è·å–ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ raw_data ä¸­çš„æœ€æ–°å€¼
    # ä¿®å¤ï¼šicon å­—æ®µæ˜ å°„ - ä½¿ç”¨ validation_aliasï¼Œæ‰€ä»¥è¿™é‡Œç”¨ image_url
    card_dict = {
        "id": card.polymarket_id,  # ä½¿ç”¨ id ä½œä¸ºå…¬å¼€å­—æ®µå
        "slug": card.slug,
        "title": card.title,
        "description": card.description or raw_data.get("description"),
        "image_url": card.image_url or raw_data.get("image") or raw_data.get("icon"),  # ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ imageï¼Œå…¶æ¬¡ icon
        "volume": float(card.volume) if card.volume else (float(raw_data.get("volume", 0)) if raw_data.get("volume") else None),
        "liquidity": float(raw_data.get("liquidity", 0)) if raw_data.get("liquidity") else None,
        "active": card.is_active,
        "closed": raw_data.get("closed", False),
        "startDate": format_date(raw_data.get("startDate")),
        "endDate": format_date(raw_data.get("endDate")) or format_date(card.end_date),
        "createdAt": card.created_at.isoformat() if card.created_at else None,  # ä¿®å¤ï¼šæ·»åŠ  createdAt
        "updatedAt": card.updated_at.isoformat() if card.updated_at else None,  # ä¿®å¤ï¼šæ·»åŠ  updatedAt
        "tags": _extract_tags_from_raw_data(raw_data),
        "markets": _extract_markets_from_raw_data(raw_data, ai_markets),
        "aILogicSummary": ai_logic_summary,  # AI åˆ†ææ‘˜è¦
        "adjustedProbability": adjusted_probability,  # AI è°ƒæ•´åçš„æ¦‚ç‡
    }
    return card_dict


@router.get("/list", response_model=CardListResponse)
@profile_endpoint
async def get_card_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    pageSize: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    tagId: Optional[str] = Query(None, description="æ ‡ç­¾ ID è¿‡æ»¤"),
    sortBy: str = Query("volume", pattern="^(volume|liquidity)$", description="æ’åºå­—æ®µ"),
    order: str = Query("desc", pattern="^(asc|desc)$", description="æ’åºæ–¹å‘"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡åˆ—è¡¨
    
    - **page**: é¡µç ï¼ˆä» 1 å¼€å§‹ï¼‰
    - **pageSize**: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - **tagId**: å¯é€‰çš„æ ‡ç­¾ ID è¿‡æ»¤
    - **sortBy**: æ’åºå­—æ®µï¼ˆvolume æˆ– liquidityï¼‰
    - **order**: æ’åºæ–¹å‘ï¼ˆasc æˆ– descï¼‰
    """
    print(f"\nâ±ï¸ === å¼€å§‹è¯¦ç»†æ€§èƒ½è¯Šæ–­ (Page: {page}, PageSize: {pageSize}) ===")
    overall_start = time.perf_counter()

    try:
        # -------- 1. æ„å»ºåŸºç¡€æŸ¥è¯¢ï¼ˆç”¨äºåˆ—è¡¨æ•°æ®ï¼‰ï¼Œå¹¶é¢„åŠ è½½å…³ç³»ä»¥é¿å… N+1 --------
        t_query_build_start = time.perf_counter()
        
        # ä¼˜åŒ–ï¼šä½¿ç”¨ LEFT JOIN + IS NULL ä»£æ›¿ NOT INï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
        # å­æŸ¥è¯¢ï¼šæ‰¾å‡º sports æ ‡ç­¾çš„ ID
        from sqlalchemy.orm import aliased
        sports_card_tags = aliased(card_tags, name="sports_ct")
        sports_tag_ids = select(Tag.id).where(Tag.name.ilike("%sport%")).scalar_subquery()
        
        base_query = (
            select(EventCard)
            .outerjoin(
                sports_card_tags,
                (EventCard.id == sports_card_tags.c.card_id) & 
                (sports_card_tags.c.tag_id.in_(select(Tag.id).where(Tag.name.ilike("%sport%"))))
            )
            .options(
                selectinload(EventCard.tags),
                selectinload(EventCard.predictions),
            )
            .where(EventCard.is_active == True)
            .where(EventCard.is_active.isnot(None))
            .where(EventCard.is_closed == False)
            .where(EventCard.is_closed.isnot(None))
            .where(EventCard.is_archived == False)
            .where(EventCard.is_archived.isnot(None))
            .where(sports_card_tags.c.card_id.is_(None))  # æ’é™¤æœ‰ sports æ ‡ç­¾çš„
        )

        # æ ‡ç­¾è¿‡æ»¤ï¼ˆä½¿ç”¨ Polymarket åŸå§‹ tag idï¼‰
        if tagId:
            base_query = base_query.join(
                card_tags, EventCard.id == card_tags.c.card_id
            ).join(
                Tag, card_tags.c.tag_id == Tag.id
            ).where(Tag.polymarket_id == str(tagId))
        t_query_build_end = time.perf_counter()
        print(f"ğŸ“‹ [Step 0] æŸ¥è¯¢æ„å»ºè€—æ—¶: {(t_query_build_end - t_query_build_start) * 1000:.2f}ms")

        # -------- 2. Count æŸ¥è¯¢ï¼šä¸ base_query è¿‡æ»¤æ¡ä»¶ä¸€è‡´ --------
        t_count_start = time.perf_counter()
        # åŸºç¡€è¿‡æ»¤æ¡ä»¶ï¼ˆä¸ base_query ä¸€è‡´ï¼‰
        base_filters = [
            EventCard.is_active == True,
            EventCard.is_active.isnot(None),
            EventCard.is_closed == False,
            EventCard.is_closed.isnot(None),
            EventCard.is_archived == False,
            EventCard.is_archived.isnot(None),
        ]
        
        if tagId:
            # æ ‡ç­¾è¿‡æ»¤ï¼šä½¿ç”¨ COUNT(DISTINCT) é¿å… JOIN å¯¼è‡´çš„é‡å¤è®¡æ•°
            count_query = (
                select(func.count(func.distinct(EventCard.id)))
                .select_from(EventCard)
                .outerjoin(
                    sports_card_tags,
                    (EventCard.id == sports_card_tags.c.card_id) & 
                    (sports_card_tags.c.tag_id.in_(select(Tag.id).where(Tag.name.ilike("%sport%"))))
                )
                .join(card_tags, EventCard.id == card_tags.c.card_id)
                .join(Tag, card_tags.c.tag_id == Tag.id)
                .where(*base_filters)
                .where(sports_card_tags.c.card_id.is_(None))
                .where(Tag.polymarket_id == str(tagId))
            )
        else:
            # æ— æ ‡ç­¾è¿‡æ»¤ï¼šæ’é™¤ sports + åŸºç¡€è¿‡æ»¤
            count_query = (
                select(func.count(func.distinct(EventCard.id)))
                .select_from(EventCard)
                .outerjoin(
                    sports_card_tags,
                    (EventCard.id == sports_card_tags.c.card_id) & 
                    (sports_card_tags.c.tag_id.in_(select(Tag.id).where(Tag.name.ilike("%sport%"))))
                )
                .where(*base_filters)
                .where(sports_card_tags.c.card_id.is_(None))
            )
        
        # ç›´æ¥æ‰§è¡Œ count æŸ¥è¯¢
        total_result = await db.execute(count_query)
        total_count = total_result.scalar_one() or 0
        t_count_end = time.perf_counter()
        print(f"ğŸ“Š [Step 1] Count æŸ¥è¯¢è€—æ—¶: {(t_count_end - t_count_start) * 1000:.2f}ms (Total: {total_count})")

        # -------- 3. æ’åºä¼˜åŒ–ï¼šå…ˆæŒ‰ volume DESC è·å–å€™é€‰é›†ï¼ˆæœ€çƒ­ 100 æ¡ï¼‰ --------
        # æ··åˆæ’åºéœ€è¦åœ¨å€™é€‰é›†ä¸Šè¿›è¡Œï¼Œè€Œä¸æ˜¯ç›´æ¥åˆ†é¡µ
        CANDIDATE_POOL_SIZE = 100  # å€™é€‰æ± å¤§å°ï¼Œé¿å…å¯¹å…¨åº“é‡è®¡ç®—
        
        query = base_query.order_by(desc(EventCard.volume)).limit(CANDIDATE_POOL_SIZE)

        # -------- 5. è¯Šæ–­ Main Query (DB + ç½‘ç»œ) è€—æ—¶ --------
        t_query_start = time.perf_counter()
        result = await db.execute(query)
        cards = result.scalars().all()
        t_query_end = time.perf_counter()
        print(f"ğŸ¢ [Step 2] åˆ—è¡¨ SQL æ‰§è¡Œ + ç½‘ç»œä¼ è¾“: {(t_query_end - t_query_start) * 1000:.2f}ms (Cards: {len(cards)})")

        # -------- 6. ä¼˜åŒ– Snapshot æŸ¥è¯¢ï¼šä½¿ç”¨çª—å£å‡½æ•°è·å–æœ€æ–°å¿«ç…§ --------
        t_snap_start = time.perf_counter()
        card_data_list = []
        if cards:
            polymarket_ids = [card.polymarket_id for card in cards]

            # ä½¿ç”¨çª—å£å‡½æ•°å­æŸ¥è¯¢ï¼šä¸ºæ¯ä¸ª polymarket_id æ‰¾åˆ°æœ€æ–°çš„ created_at
            # ç„¶å JOIN å›åŸè¡¨è·å–å®Œæ•´è®°å½•ï¼ˆæ¯”å¾ªç¯è¿‡æ»¤å¿«å¾—å¤šï¼‰
            from sqlalchemy import text
            # ä½¿ç”¨ PostgreSQL çš„ DISTINCT ONï¼ˆæ€§èƒ½æœ€ä¼˜ï¼Œä½†éœ€è¦åŸç”Ÿ SQLï¼‰
            snapshots_query = text("""
                SELECT DISTINCT ON (polymarket_id) 
                    id, polymarket_id, raw_data, created_at
                FROM event_snapshots
                WHERE polymarket_id = ANY(:ids)
                ORDER BY polymarket_id, created_at DESC
            """)
            
            snapshots_result = await db.execute(
                snapshots_query, {"ids": polymarket_ids}
            )
            snapshots_rows = snapshots_result.mappings().all()

            # å°†ç»“æœæ˜ å°„å›å­—å…¸æ ¼å¼ï¼ˆç›´æ¥ä½¿ç”¨ raw_dataï¼Œæ— éœ€åˆ›å»º EventSnapshot å¯¹è±¡ï¼‰
            latest_snapshot_by_id: dict[str, dict] = {}
            for row in snapshots_rows:
                latest_snapshot_by_id[row["polymarket_id"]] = {
                    "raw_data": row["raw_data"],
                    "created_at": row["created_at"],
                }

            # æ„å»ºå¡ç‰‡æ•°æ®
            t_build_start = time.perf_counter()
            for card in cards:
                snapshot_data = latest_snapshot_by_id.get(card.polymarket_id)
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ EventSnapshot å¯¹è±¡ç”¨äº _build_card_data
                snapshot = None
                if snapshot_data:
                    snapshot = EventSnapshot(
                        polymarket_id=card.polymarket_id,
                        raw_data=snapshot_data["raw_data"],
                        created_at=snapshot_data["created_at"],
                    )
                # ä¼ å…¥ predictionsï¼ˆå·²é€šè¿‡ selectinload é¢„åŠ è½½ï¼ŒæŒ‰ created_at é™åºæ’åºï¼‰
                card_dict = _build_card_data(card, snapshot, card.predictions)
                card_data_list.append(card_dict)
            t_build_end = time.perf_counter()
            print(f"ğŸ”„ [Step 3] Snapshot æ‰¹é‡æŸ¥è¯¢: {(t_build_start - t_snap_start) * 1000:.2f}ms")
            print(f"   ğŸ“¦ [Step 3.1] æ•°æ®æ„å»ºè€—æ—¶: {(t_build_end - t_build_start) * 1000:.2f}ms")
        t_snap_end = time.perf_counter()
        print(f"ğŸ”„ [Step 3 Total] Snapshot å¤„ç†æ€»è€—æ—¶: {(t_snap_end - t_snap_start) * 1000:.2f}ms")

        # -------- 7. æ··åˆåŠ æƒæ’åºï¼švolume + AI alpha (æ€§èƒ½ä¼˜åŒ–ç‰ˆ) --------
        t_sort_start = time.perf_counter()

        def _normalize_prob(val) -> float:
            """å½’ä¸€åŒ–æ¦‚ç‡åˆ° 0.0-1.0 èŒƒå›´"""
            if val is None:
                return 0.0
            v = float(val)
            if v > 1.0:
                v = v / 100.0
            return max(0.0, min(1.0, v))

        # === é¢„è®¡ç®—é˜¶æ®µï¼šä¸€æ¬¡æ€§ä¸ºæ‰€æœ‰å¡ç‰‡è®¡ç®—åˆ†æ•°ï¼Œé¿å… sorted() å†…é‡å¤è®¡ç®— ===
        for card in card_data_list:
            # 1. Volume Scoreï¼ˆæ˜¾å¼ float è½¬æ¢ï¼‰
            vol = float(card.get("volume") or 0)
            card["_volume_score"] = round(vol, 2)
            
            # 2. Alpha Score = volume Ã— max_diffï¼ˆé¢„è®¡ç®—å½’ä¸€åŒ–å·®å€¼ï¼‰
            alpha_score = 0.0
            if vol > 0:
                diffs = []
                for m in card.get("markets", []):
                    prob = _normalize_prob(m.get("probability", 0.0))
                    adj_prob = m.get("ai_adjusted_probability") or m.get("adjustedProbability")
                    if adj_prob is None:
                        curr_ai = prob  # æ—  AI æ•°æ®æ—¶ï¼Œdiff = 0
                    else:
                        curr_ai = _normalize_prob(adj_prob)
                    diff = abs(prob - curr_ai)
                    diffs.append(diff)
                # å–æœ€å¤§çš„ä¸¤ä¸ªå·®å€¼
                diffs.sort(reverse=True)
                top_diffs = diffs[:2] if len(diffs) >= 2 else diffs
                # æ˜¾å¼ float è½¬æ¢ + round é˜²æ­¢ Decimal ç²¾åº¦æŠ–åŠ¨
                alpha_score = round(float(vol) * float(sum(top_diffs)), 2)
            card["_alpha_score"] = alpha_score

        # === éªŒè¯é˜¶æ®µï¼šç¡®ä¿é¢„è®¡ç®—åˆ†æ•°æ—  None ===
        for card in card_data_list:
            assert card.get("_volume_score") is not None, f"_volume_score is None for {card.get('id')}"
            assert card.get("_alpha_score") is not None, f"_alpha_score is None for {card.get('id')}"
            assert isinstance(card["_alpha_score"], (int, float)), f"_alpha_score is not float: {type(card['_alpha_score'])}"

        # === æ’åºé˜¶æ®µï¼šç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„åˆ†æ•°ï¼ˆO(1) è®¿é—®ï¼‰ ===
        list_volume = sorted(card_data_list, key=lambda c: c["_volume_score"], reverse=True)
        list_alpha = sorted(card_data_list, key=lambda c: c["_alpha_score"], reverse=True)

        # è°ƒè¯•ï¼šæ‰“å°å‰ 5 åçš„æ’åºæƒ…å†µï¼ˆå«åˆ†æ•°ï¼‰
        print(f"   ğŸ“Š Volume Top5: {[(c.get('id')[:8], c['_volume_score']) for c in list_volume[:5]]}")
        print(f"   ğŸ“Š Alpha Top5:  {[(c.get('id')[:8], c['_alpha_score']) for c in list_alpha[:5]]}")
        
        # éªŒè¯ï¼šæ£€æŸ¥ Volume å’Œ Alpha Top10 æ˜¯å¦å®Œå…¨ä¸€è‡´ï¼ˆç”¨äºæµ‹è¯•å»é‡é€»è¾‘ï¼‰
        vol_top10_ids = [c.get('id') for c in list_volume[:10]]
        alpha_top10_ids = [c.get('id') for c in list_alpha[:10]]
        overlap_count = len(set(vol_top10_ids) & set(alpha_top10_ids))
        print(f"   ğŸ” Top10 é‡å åº¦: {overlap_count}/10 (ç›¸åŒäº‹ä»¶æ•°)")

        # ç²¾ç¡®äº¤æ›¿æ’å€¼ï¼šIndex 0 -> volume[0], Index 1 -> alpha[0], Index 2 -> volume[1], ...
        final_list = []
        used_ids = set()
        ptr_vol, ptr_alpha = 0, 0
        turn_volume = True  # ä» volume å¼€å§‹
        target_size = len(card_data_list)

        while len(final_list) < target_size:
            added = False
            
            if turn_volume:
                # ä» list_volume å–ä¸‹ä¸€ä¸ªæœªä½¿ç”¨çš„
                while ptr_vol < len(list_volume):
                    card = list_volume[ptr_vol]
                    ptr_vol += 1
                    if card.get("id") not in used_ids:
                        final_list.append(card)
                        used_ids.add(card.get("id"))
                        added = True
                        break
            else:
                # ä» list_alpha å–ä¸‹ä¸€ä¸ªæœªä½¿ç”¨çš„ï¼ˆå»é‡ä¿æŠ¤ï¼šè‡ªåŠ¨é¡ºå»¶ï¼‰
                while ptr_alpha < len(list_alpha):
                    card = list_alpha[ptr_alpha]
                    ptr_alpha += 1
                    if card.get("id") not in used_ids:
                        final_list.append(card)
                        used_ids.add(card.get("id"))
                        added = True
                        break
            
            # äº¤æ›¿åˆ‡æ¢
            turn_volume = not turn_volume
            
            # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœä¸¤ä¸ªåˆ—è¡¨éƒ½è€—å°½ä¸”æ²¡æœ‰æ·»åŠ æ–°å…ƒç´ ï¼Œé€€å‡ºå¾ªç¯
            if not added and ptr_vol >= len(list_volume) and ptr_alpha >= len(list_alpha):
                break

        # -------- 8. åº”ç”¨åˆ†é¡µï¼ˆåœ¨æ··åˆæ’åºåï¼‰ --------
        offset = (page - 1) * pageSize
        card_data_list = final_list[offset:offset + pageSize]
        
        t_sort_end = time.perf_counter()
        print(f"ğŸ”€ [Step 4] æ··åˆåŠ æƒæ’åºå®Œæˆ: {(t_sort_end - t_sort_start) * 1000:.2f}ms (å€™é€‰æ± : {len(final_list)}, è¿”å›: {len(card_data_list)})")
        
        # è°ƒè¯•ï¼šæ‰“å°å½“å‰é¡µçš„äº¤æ›¿æƒ…å†µï¼ˆå‰ 10 æ¡ï¼‰
        debug_slice = final_list[offset:offset + min(10, pageSize)]
        for i, c in enumerate(debug_slice):
            src = "VOL" if i % 2 == 0 else "ALP"
            print(f"   [{offset + i}] {src}: {c.get('id')[:12]}... vol={c.get('volume', 0):.0f}")

        # -------- 9. è¯Šæ–­ Pydantic åºåˆ—åŒ–è€—æ—¶ --------
        t_serialize_start = time.perf_counter()
        card_data_objects = [CardData(**item) for item in card_data_list]
        t_serialize_end = time.perf_counter()
        print(f"ğŸ§  [Step 5] Pydantic åºåˆ—åŒ– (CPU): {(t_serialize_end - t_serialize_start) * 1000:.2f}ms")

        # æ„å»ºç¬¦åˆå‰ç«¯æœŸæœ›ç»“æ„çš„åˆ†é¡µè½½ä½“
        payload = CardListPayload(
            total=total_count,
            page=page,
            pageSize=pageSize,
            list=card_data_objects,
        )

        overall_end = time.perf_counter()
        print(f"ğŸ [Total] æ€»æ¥å£é€»è¾‘è€—æ—¶: {(overall_end - overall_start) * 1000:.2f}ms")
        print("=" * 60 + "\n")

        return CardListResponse(
            code=200,
            message="success",
            data=payload,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/details", response_model=CardDetailsResponse)
@profile_endpoint
async def get_card_details(
    id: str = Query(..., description="Polymarket Event ID"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡è¯¦æƒ…
    
    - **id**: Polymarket Event IDï¼ˆå¯¹åº” EventCard.polymarket_idï¼‰
    """
    try:
        # æŸ¥è¯¢ EventCardï¼Œé¢„åŠ è½½ predictions
        card_query = (
            select(EventCard)
            .options(selectinload(EventCard.predictions))
            .where(EventCard.polymarket_id == id)
        )
        card_result = await db.execute(card_query)
        card = card_result.scalar_one_or_none()

        if not card:
            raise HTTPException(status_code=404, detail=f"Card with id '{id}' not found")

        # è·å–æœ€æ–°çš„ EventSnapshot
        snapshot_query = (
            select(EventSnapshot)
            .where(EventSnapshot.polymarket_id == id)
            .order_by(desc(EventSnapshot.created_at))
            .limit(1)
        )
        snapshot_result = await db.execute(snapshot_query)
        snapshot = snapshot_result.scalar_one_or_none()

        card_dict = _build_card_data(card, snapshot, card.predictions)

        return CardDetailsResponse(
            code=200,
            message="success",
            data=CardData(**card_dict),
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


