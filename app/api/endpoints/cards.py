"""Card API ç«¯ç‚¹"""
import time
from typing import Optional

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import desc, func, select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.decorators import profile_endpoint
from app.db.session import get_db
from app.models.ai_prediction import AIPrediction
from app.models.card_tag import card_tags
from app.models.event_card import EventCard
from app.models.event_snapshot import EventSnapshot
from app.models.tag import Tag
from app.schemas.card import (
    CardData,
    CardDetailsResponse,
    CardListPayload,
    CardListResponse,
)

router = APIRouter()


def _extract_markets_from_raw_data(raw_data: dict, ai_markets: dict = None) -> list:
    """ä» raw_data ä¸­æå– markets åˆ—è¡¨ï¼Œå¹¶åˆå¹¶ AI åˆ†ææ•°æ®"""
    markets = raw_data.get("markets", [])
    ai_markets = ai_markets or {}
    result = []
    for market in markets:
        market_id = market.get("id", "")
        # æå–æ‰€æœ‰å…³é”®å­—æ®µï¼ŒåŒ…æ‹¬æ–°å¢çš„å­—æ®µ
        market_data = {
            "id": market_id,
            "question": market.get("question", ""),
            "outcomes": market.get("outcomes", []),
            "currentPrices": market.get("currentPrices", {}),
            "volume": market.get("volume"),
            "liquidity": market.get("liquidity"),  # Market çº§åˆ«çš„ liquidity
            "active": market.get("active", True),
            # æ–°å¢å­—æ®µï¼ˆå‰ç«¯ Mock è¦æ±‚ï¼‰
            "groupItemTitle": market.get("groupItemTitle"),  # ä¿®å¤ï¼šæ·»åŠ  groupItemTitle
            "icon": market.get("icon"),  # Market çº§åˆ«çš„ iconï¼ˆå¦‚æœæœ‰ï¼‰
            "outcomePrices": market.get("outcomePrices"),  # ä¿®å¤ï¼šæ·»åŠ  outcomePricesï¼ˆç”¨äºè®¡ç®— probabilityï¼‰
        }
        
        # å¦‚æœæœ‰ AI åˆ†ææ•°æ®ï¼Œæ³¨å…¥ç›¸å…³å­—æ®µ
        if market_id in ai_markets:
            ai_data = ai_markets[market_id]
            
            # 1. AI è°ƒæ•´åçš„æ¦‚ç‡
            if "ai_calibrated_odds_pct" in ai_data:
                market_data["ai_adjusted_probability"] = float(ai_data["ai_calibrated_odds_pct"])
            
            # 2. AI ç½®ä¿¡åº¦ (1-10)
            if "ai_confidence" in ai_data:
                market_data["ai_confidence"] = float(ai_data["ai_confidence"])
            
            # 3. AI åˆ†æè¯¦æƒ… (æ”¯æŒå¤šç§ key æ ¼å¼)
            market_data["ai_analysis_data"] = {
                "structuralAnchor": ai_data.get("anchor") or ai_data.get("structural_anchor"),
                "noise": ai_data.get("noise") or ai_data.get("the_noise"),
                "barrier": ai_data.get("barrier") or ai_data.get("the_barrier"),
                "blindspot": ai_data.get("blindspot") or ai_data.get("the_blindspot"),
            }
        
        result.append(market_data)
    return result


def _extract_tags_from_raw_data(raw_data: dict) -> list:
    """ä» raw_data ä¸­æå– tags åˆ—è¡¨"""
    tags = raw_data.get("tags", [])
    result = []
    for tag in tags:
        result.append({
            "id": str(tag.get("id", "")),
            "label": tag.get("label", ""),
            "slug": tag.get("slug", ""),
        })
    return result


def _build_card_data(card: EventCard, snapshot: Optional[EventSnapshot] = None, predictions: Optional[list] = None) -> dict:
    """æ„å»ºå¡ç‰‡æ•°æ®å¯¹è±¡"""
    raw_data = snapshot.raw_data if snapshot else {}
    
    # æ ¼å¼åŒ–æ—¥æœŸå­—æ®µ
    def format_date(date_value):
        """æ ¼å¼åŒ–æ—¥æœŸä¸º ISO å­—ç¬¦ä¸²"""
        if date_value is None:
            return None
        if isinstance(date_value, str):
            return date_value
        # å¦‚æœæ˜¯ datetime å¯¹è±¡ï¼Œè½¬æ¢ä¸º ISO æ ¼å¼
        return date_value.isoformat() if hasattr(date_value, 'isoformat') else str(date_value)
    
    # è·å– AI é¢„æµ‹æ•°æ®ï¼ˆä»æœ€æ–°çš„ prediction ä¸­æå–ï¼‰
    ai_logic_summary = None
    adjusted_probability = None
    ai_markets = {}  # market_id -> AI åˆ†ææ•°æ®
    if predictions and len(predictions) > 0:
        # predictions åº”è¯¥æŒ‰ created_at é™åºæ’åºï¼Œå–ç¬¬ä¸€ä¸ª
        latest = predictions[0]
        ai_logic_summary = latest.summary
        # outcome_prediction å­˜çš„æ˜¯çº¯æ•°å­—ï¼Œå¦‚ "56.5"
        if latest.outcome_prediction:
            try:
                adjusted_probability = float(latest.outcome_prediction)
            except ValueError:
                adjusted_probability = None
        # è§£æ raw_analysis è·å–æ¯ä¸ª market çš„ AI æ¦‚ç‡
        if latest.raw_analysis:
            try:
                import json
                ai_markets = json.loads(latest.raw_analysis)
            except (json.JSONDecodeError, TypeError):
                ai_markets = {}
    
    # åŸºç¡€å­—æ®µä» EventCard è·å–ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ raw_data ä¸­çš„æœ€æ–°å€¼
    # ä¿®å¤ï¼šicon å­—æ®µæ˜ å°„ - ä½¿ç”¨ validation_aliasï¼Œæ‰€ä»¥è¿™é‡Œç”¨ image_url
    card_dict = {
        "id": card.polymarket_id,  # ä½¿ç”¨ id ä½œä¸ºå…¬å¼€å­—æ®µå
        "slug": card.slug,
        "title": card.title,
        "description": card.description or raw_data.get("description"),
        "image_url": card.image_url or raw_data.get("image") or raw_data.get("icon"),  # ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ imageï¼Œå…¶æ¬¡ icon
        "volume": float(card.volume) if card.volume else (float(raw_data.get("volume", 0)) if raw_data.get("volume") else None),
        "liquidity": float(raw_data.get("liquidity", 0)) if raw_data.get("liquidity") else None,
        "active": card.is_active,
        "closed": raw_data.get("closed", False),
        "startDate": format_date(raw_data.get("startDate")),
        "endDate": format_date(raw_data.get("endDate")) or format_date(card.end_date),
        "createdAt": card.created_at.isoformat() if card.created_at else None,  # ä¿®å¤ï¼šæ·»åŠ  createdAt
        "updatedAt": card.updated_at.isoformat() if card.updated_at else None,  # ä¿®å¤ï¼šæ·»åŠ  updatedAt
        "tags": _extract_tags_from_raw_data(raw_data),
        "markets": _extract_markets_from_raw_data(raw_data, ai_markets),
        "aILogicSummary": ai_logic_summary,  # AI åˆ†ææ‘˜è¦
        "adjustedProbability": adjusted_probability,  # AI è°ƒæ•´åçš„æ¦‚ç‡
    }
    return card_dict


@router.get("/list", response_model=CardListResponse)
@profile_endpoint
async def get_card_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    pageSize: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    tagId: Optional[str] = Query(None, description="æ ‡ç­¾ ID è¿‡æ»¤"),
    sortBy: str = Query("volume", pattern="^(volume|liquidity)$", description="æ’åºå­—æ®µ"),
    order: str = Query("desc", pattern="^(asc|desc)$", description="æ’åºæ–¹å‘"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡åˆ—è¡¨
    
    - **page**: é¡µç ï¼ˆä» 1 å¼€å§‹ï¼‰
    - **pageSize**: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - **tagId**: å¯é€‰çš„æ ‡ç­¾ ID è¿‡æ»¤
    - **sortBy**: æ’åºå­—æ®µï¼ˆvolume æˆ– liquidityï¼‰
    - **order**: æ’åºæ–¹å‘ï¼ˆasc æˆ– descï¼‰
    """
    print(f"\nâ±ï¸ === å¼€å§‹è¯¦ç»†æ€§èƒ½è¯Šæ–­ (Page: {page}, PageSize: {pageSize}) ===")
    overall_start = time.perf_counter()

    try:
        # -------- 1. æ„å»ºåŸºç¡€æŸ¥è¯¢ï¼ˆç”¨äºåˆ—è¡¨æ•°æ®ï¼‰ï¼Œå¹¶é¢„åŠ è½½å…³ç³»ä»¥é¿å… N+1 --------
        t_query_build_start = time.perf_counter()
        
        # å­æŸ¥è¯¢ï¼šæ‰¾å‡ºæ‰€æœ‰åŒ…å« sports æ ‡ç­¾çš„ card_id
        sports_tag_subquery = (
            select(card_tags.c.card_id)
            .join(Tag, card_tags.c.tag_id == Tag.id)
            .where(Tag.name.ilike("%sport%"))
        ).scalar_subquery()
        
        base_query = (
            select(EventCard)
            .options(
                selectinload(EventCard.tags),
                selectinload(EventCard.predictions),  # é¢„åŠ è½½ AI é¢„æµ‹ï¼Œç”¨äºè·å– aiLogicSummary
                # ç›®å‰ markets æ¥æºäº EventSnapshot.raw_dataï¼Œè¿™é‡Œæ²¡æœ‰ ORM å…³ç³»å¯é¢„åŠ è½½
                # å¦‚æœªæ¥ä¸º Market å»ºè¡¨å¹¶å»ºç«‹å…³ç³»ï¼Œå¯åœ¨æ­¤æ·»åŠ  selectinload(EventCard.markets)
            )
            .where(EventCard.is_active == True)
            .where(EventCard.id.not_in(sports_tag_subquery))  # è¿‡æ»¤ sports
        )

        # æ ‡ç­¾è¿‡æ»¤ï¼ˆä½¿ç”¨ Polymarket åŸå§‹ tag idï¼‰
        if tagId:
            base_query = base_query.join(
                card_tags, EventCard.id == card_tags.c.card_id
            ).join(
                Tag, card_tags.c.tag_id == Tag.id
            ).where(Tag.polymarket_id == str(tagId))
        t_query_build_end = time.perf_counter()
        print(f"ğŸ“‹ [Step 0] æŸ¥è¯¢æ„å»ºè€—æ—¶: {(t_query_build_end - t_query_build_start) * 1000:.2f}ms")

        # -------- 2. ä¼˜åŒ– Count æŸ¥è¯¢ï¼šç›´æ¥è®¡æ•°ï¼Œé¿å…å­æŸ¥è¯¢å’Œæ’åº --------
        t_count_start = time.perf_counter()
        # æ„å»ºå¹²å‡€çš„ count æŸ¥è¯¢ï¼Œå®Œå…¨ä¸ä¾èµ– base_queryï¼Œé¿å…ä»»ä½•å­æŸ¥è¯¢å¼€é”€
        if tagId:
            # æ ‡ç­¾è¿‡æ»¤ï¼šä½¿ç”¨ COUNT(DISTINCT) é¿å… JOIN å¯¼è‡´çš„é‡å¤è®¡æ•°
            count_query = (
                select(func.count(func.distinct(EventCard.id)))
                .select_from(EventCard)
                .join(card_tags, EventCard.id == card_tags.c.card_id)
                .join(Tag, card_tags.c.tag_id == Tag.id)
                .where(EventCard.is_active == True)
                .where(Tag.polymarket_id == str(tagId))
            )
        else:
            # æ— è¿‡æ»¤ï¼šç›´æ¥è®¡æ•°ï¼Œæœ€ç®€å•æœ€å¿«
            count_query = (
                select(func.count(EventCard.id))
                .where(EventCard.is_active == True)
            )
        
        # ç›´æ¥æ‰§è¡Œ count æŸ¥è¯¢
        total_result = await db.execute(count_query)
        total_count = total_result.scalar_one() or 0
        t_count_end = time.perf_counter()
        print(f"ğŸ“Š [Step 1] Count æŸ¥è¯¢è€—æ—¶: {(t_count_end - t_count_start) * 1000:.2f}ms (Total: {total_count})")

        # -------- 3. æ’åºï¼ˆä»åœ¨ SQL å±‚é¢ï¼‰ --------
        query = base_query
        # æ³¨æ„ï¼šliquidity å­˜å‚¨åœ¨ raw_data ä¸­ï¼Œæ— æ³•ç›´æ¥åœ¨ SQL å±‚é¢æ’åº
        # å¦‚æœæŒ‰ liquidity æ’åºï¼Œéœ€è¦åœ¨ Python å±‚é¢å¤„ç†
        if sortBy == "volume":
            sort_column = EventCard.volume
            if order == "desc":
                query = query.order_by(desc(sort_column))
            else:
                query = query.order_by(sort_column)
        else:  # liquidity - éœ€è¦åœ¨è·å–æ•°æ®åæ’åº
            # å…ˆæŒ‰ volume æ’åºä½œä¸ºé»˜è®¤ï¼Œç„¶ååœ¨ Python å±‚é¢é‡æ–°æ’åº
            query = query.order_by(desc(EventCard.volume))

        # -------- 4. åˆ†é¡µ --------
        offset = (page - 1) * pageSize
        query = query.offset(offset).limit(pageSize)

        # -------- 5. è¯Šæ–­ Main Query (DB + ç½‘ç»œ) è€—æ—¶ --------
        t_query_start = time.perf_counter()
        result = await db.execute(query)
        cards = result.scalars().all()
        t_query_end = time.perf_counter()
        print(f"ğŸ¢ [Step 2] åˆ—è¡¨ SQL æ‰§è¡Œ + ç½‘ç»œä¼ è¾“: {(t_query_end - t_query_start) * 1000:.2f}ms (Cards: {len(cards)})")

        # -------- 6. ä¼˜åŒ– Snapshot æŸ¥è¯¢ï¼šä½¿ç”¨çª—å£å‡½æ•°è·å–æœ€æ–°å¿«ç…§ --------
        t_snap_start = time.perf_counter()
        card_data_list = []
        if cards:
            polymarket_ids = [card.polymarket_id for card in cards]

            # ä½¿ç”¨çª—å£å‡½æ•°å­æŸ¥è¯¢ï¼šä¸ºæ¯ä¸ª polymarket_id æ‰¾åˆ°æœ€æ–°çš„ created_at
            # ç„¶å JOIN å›åŸè¡¨è·å–å®Œæ•´è®°å½•ï¼ˆæ¯”å¾ªç¯è¿‡æ»¤å¿«å¾—å¤šï¼‰
            from sqlalchemy import text
            # ä½¿ç”¨ PostgreSQL çš„ DISTINCT ONï¼ˆæ€§èƒ½æœ€ä¼˜ï¼Œä½†éœ€è¦åŸç”Ÿ SQLï¼‰
            snapshots_query = text("""
                SELECT DISTINCT ON (polymarket_id) 
                    id, polymarket_id, raw_data, created_at
                FROM event_snapshots
                WHERE polymarket_id = ANY(:ids)
                ORDER BY polymarket_id, created_at DESC
            """)
            
            snapshots_result = await db.execute(
                snapshots_query, {"ids": polymarket_ids}
            )
            snapshots_rows = snapshots_result.mappings().all()

            # å°†ç»“æœæ˜ å°„å›å­—å…¸æ ¼å¼ï¼ˆç›´æ¥ä½¿ç”¨ raw_dataï¼Œæ— éœ€åˆ›å»º EventSnapshot å¯¹è±¡ï¼‰
            latest_snapshot_by_id: dict[str, dict] = {}
            for row in snapshots_rows:
                latest_snapshot_by_id[row["polymarket_id"]] = {
                    "raw_data": row["raw_data"],
                    "created_at": row["created_at"],
                }

            # æ„å»ºå¡ç‰‡æ•°æ®
            t_build_start = time.perf_counter()
            for card in cards:
                snapshot_data = latest_snapshot_by_id.get(card.polymarket_id)
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ EventSnapshot å¯¹è±¡ç”¨äº _build_card_data
                snapshot = None
                if snapshot_data:
                    snapshot = EventSnapshot(
                        polymarket_id=card.polymarket_id,
                        raw_data=snapshot_data["raw_data"],
                        created_at=snapshot_data["created_at"],
                    )
                # ä¼ å…¥ predictionsï¼ˆå·²é€šè¿‡ selectinload é¢„åŠ è½½ï¼ŒæŒ‰ created_at é™åºæ’åºï¼‰
                card_dict = _build_card_data(card, snapshot, card.predictions)
                card_data_list.append(card_dict)
            t_build_end = time.perf_counter()
            print(f"ğŸ”„ [Step 3] Snapshot æ‰¹é‡æŸ¥è¯¢: {(t_build_start - t_snap_start) * 1000:.2f}ms")
            print(f"   ğŸ“¦ [Step 3.1] æ•°æ®æ„å»ºè€—æ—¶: {(t_build_end - t_build_start) * 1000:.2f}ms")
        t_snap_end = time.perf_counter()
        print(f"ğŸ”„ [Step 3 Total] Snapshot å¤„ç†æ€»è€—æ—¶: {(t_snap_end - t_snap_start) * 1000:.2f}ms")

        # -------- 7. äº¤æ›¿æ’åºï¼šå•æ•°ä½ç½®æŒ‰ volumeï¼ŒåŒæ•°ä½ç½®æŒ‰ AI å·®å€¼ --------
        t_sort_start = time.perf_counter()
        
        def calc_ai_diff(card_dict):
            """è®¡ç®— AI é¢„æµ‹ä¸åŸå§‹æ•°æ®çš„å·®å€¼ç»å¯¹å€¼ä¹‹å’Œ"""
            total_diff = 0.0
            markets = card_dict.get("markets", [])
            for m in markets:
                prob = m.get("probability", 0) or 0
                adj_prob = m.get("adjustedProbability", prob) or prob
                # è®¡ç®—å•ä¸ªå¸‚åœºçš„å·®å€¼ï¼ˆåŸå§‹å’Œ AI éƒ½æœ‰ Yes/No ä¸¤é¢ï¼‰
                diff = abs(prob - adj_prob)
                total_diff += diff * 2  # Yes å’Œ No çš„å·®å€¼æ€»å’Œ
            return total_diff
        
        # æŒ‰ volume é™åºæ’åºçš„åˆ—è¡¨
        volume_sorted = sorted(card_data_list, key=lambda x: x.get("volume") or 0, reverse=True)
        
        # æŒ‰ AI å·®å€¼é™åºæ’åºçš„åˆ—è¡¨ï¼ˆå·®å€¼è¶Šå¤§è¶Šæœ‰"æ´å¯Ÿ"ï¼‰
        diff_sorted = sorted(card_data_list, key=calc_ai_diff, reverse=True)
        
        # å»é‡é›†åˆï¼Œé˜²æ­¢é‡å¤æ·»åŠ 
        used_ids = set()
        interleaved_list = []
        
        vol_idx, diff_idx = 0, 0
        position = 1  # ä»ä½ç½® 1 å¼€å§‹
        
        while len(interleaved_list) < len(card_data_list):
            if position % 2 == 1:  # å•æ•°ä½ç½®ï¼švolume
                while vol_idx < len(volume_sorted):
                    card = volume_sorted[vol_idx]
                    vol_idx += 1
                    card_id = card.get("id")
                    if card_id not in used_ids:
                        used_ids.add(card_id)
                        interleaved_list.append(card)
                        break
            else:  # åŒæ•°ä½ç½®ï¼šAI å·®å€¼
                while diff_idx < len(diff_sorted):
                    card = diff_sorted[diff_idx]
                    diff_idx += 1
                    card_id = card.get("id")
                    if card_id not in used_ids:
                        used_ids.add(card_id)
                        interleaved_list.append(card)
                        break
            position += 1
        
        card_data_list = interleaved_list
        t_sort_end = time.perf_counter()
        print(f"ğŸ”€ [Step 4] äº¤æ›¿æ’åºè€—æ—¶: {(t_sort_end - t_sort_start) * 1000:.2f}ms")

        # -------- 8. è¯Šæ–­ Pydantic åºåˆ—åŒ–è€—æ—¶ --------
        t_serialize_start = time.perf_counter()
        card_data_objects = [CardData(**item) for item in card_data_list]
        t_serialize_end = time.perf_counter()
        print(f"ğŸ§  [Step 5] Pydantic åºåˆ—åŒ– (CPU): {(t_serialize_end - t_serialize_start) * 1000:.2f}ms")

        # æ„å»ºç¬¦åˆå‰ç«¯æœŸæœ›ç»“æ„çš„åˆ†é¡µè½½ä½“
        payload = CardListPayload(
            total=total_count,
            page=page,
            pageSize=pageSize,
            list=card_data_objects,
        )

        overall_end = time.perf_counter()
        print(f"ğŸ [Total] æ€»æ¥å£é€»è¾‘è€—æ—¶: {(overall_end - overall_start) * 1000:.2f}ms")
        print("=" * 60 + "\n")

        return CardListResponse(
            code=200,
            message="success",
            data=payload,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/details", response_model=CardDetailsResponse)
@profile_endpoint
async def get_card_details(
    id: str = Query(..., description="Polymarket Event ID"),
    db: AsyncSession = Depends(get_db),
):
    """
    è·å–å¡ç‰‡è¯¦æƒ…
    
    - **id**: Polymarket Event IDï¼ˆå¯¹åº” EventCard.polymarket_idï¼‰
    """
    try:
        # æŸ¥è¯¢ EventCardï¼Œé¢„åŠ è½½ predictions
        card_query = (
            select(EventCard)
            .options(selectinload(EventCard.predictions))
            .where(EventCard.polymarket_id == id)
        )
        card_result = await db.execute(card_query)
        card = card_result.scalar_one_or_none()

        if not card:
            raise HTTPException(status_code=404, detail=f"Card with id '{id}' not found")

        # è·å–æœ€æ–°çš„ EventSnapshot
        snapshot_query = (
            select(EventSnapshot)
            .where(EventSnapshot.polymarket_id == id)
            .order_by(desc(EventSnapshot.created_at))
            .limit(1)
        )
        snapshot_result = await db.execute(snapshot_query)
        snapshot = snapshot_result.scalar_one_or_none()

        card_dict = _build_card_data(card, snapshot, card.predictions)

        return CardDetailsResponse(
            code=200,
            message="success",
            data=CardData(**card_dict),
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


