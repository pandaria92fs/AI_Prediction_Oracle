import asyncio
import httpx
import time
import random
import json
from datetime import datetime
from typing import List, Dict, Any

from sqlalchemy import select, delete
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.dialects.postgresql import insert

from app.db.session import async_session_factory
from app.models import EventSnapshot, EventCard, Tag, CardTag, AIPrediction
from app.services.gemini_analyzer import ai_analyzer

# --- é…ç½®åŒºåŸŸ ---
POLYMARKET_API_URL = "https://gamma-api.polymarket.com/events"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
# âš ï¸ å¦‚æœä½ çš„ä»£ç†ç«¯å£ä¸æ˜¯ 7890ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹
PROXY_URL = "http://127.0.0.1:7890" 

class PolymarketCrawler:
    def __init__(self):
        # é…ç½®ä»£ç†å’Œè¶…æ—¶
        self.client = httpx.AsyncClient(
            timeout=30.0, 
            headers=HEADERS,
            # proxies={
            #     "http://": PROXY_URL,
            #     "https://": PROXY_URL,
            # }
        )

    async def fetch_page(self, limit: int = 50, offset: int = 0):
        """æŠ“å–å•é¡µæ•°æ® (å¸¦è®¡æ—¶)"""
        params = {
            "active": "true",
            "closed": "false",
            "limit": limit,
            "offset": offset,
            "order": "volume",
            "ascending": "false",
        }

        try:
            print(f"ğŸ•·ï¸ [Offset {offset}] å‡†å¤‡å‘èµ·è¯·æ±‚...")
            
            # â±ï¸ è®¡æ—¶ç‚¹ 1: API è¯·æ±‚
            t_start = time.time()
            response = await self.client.get(POLYMARKET_API_URL, params=params)
            t_net = time.time()
            
            # æ‰“å° API è€—æ—¶
            duration = t_net - t_start
            print(f"   ğŸ“¡ [ç½‘ç»œ] Polymarket API è€—æ—¶: {duration:.2f}s")
            
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ [Offset {offset}] æŠ“å–å¤±è´¥: {str(e)}")
            return []

    async def save_batch(self, events_data: List[Dict[str, Any]]):
        """åˆ†æ‰¹å­˜å…¥æ•°æ®åº“ (ä¿®å¤æ­»é”ç‰ˆï¼šæ‰¹é‡å¤„ç† Tags)"""
        if not events_data:
            return

        t_start = time.time()
        
        # æ”¶é›† card_id æ˜ å°„ï¼Œç”¨äº AI åˆ†æ (å®šä¹‰åœ¨ session å¤–éƒ¨ä»¥ä¾¿ä¼ é€’)
        event_card_ids: dict[str, int] = {}

        async with async_session_factory() as session:
            try:
                # =================================================
                # ç¬¬ä¸€æ­¥ï¼šæå–æ‰€æœ‰ Tags å¹¶æ‰¹é‡å¤„ç† (è§£å†³æ­»é”æ ¸å¿ƒ)
                # =================================================
                # 1. æ”¶é›†æœ¬æ‰¹æ¬¡æ‰€æœ‰ç”¨åˆ°çš„æ ‡ç­¾ (polymarket_id, slug)
                #    - polymarket_id: ä¸Šæ¸¸ Polymarket çš„æ ‡ç­¾ IDï¼ˆå­—ç¬¦ä¸²ï¼‰
                #    - slug: ä½œä¸ºæœ¬åœ° Tag.name å­˜å‚¨
                all_tags: dict[str, str] = {}  # polymarket_id -> slug
                for event in events_data:
                    for t in event.get("tags", []):
                        poly_tag_id = t.get("id")
                        slug = t.get("slug")
                        if poly_tag_id is None or not slug:
                            continue
                        poly_tag_id_str = str(poly_tag_id)
                        all_tags[poly_tag_id_str] = slug
                
                # 2. æŒ‰ polymarket_id æ’åº (å…³é”®ï¼é˜²æ­¢æ­»é”)
                sorted_poly_ids = sorted(all_tags.keys())

                tag_map: dict[str, int] = {}  # å­˜æ”¾ polymarket_id -> æœ¬åœ° tag.id çš„æ˜ å°„

                if sorted_poly_ids:
                    # 3. æ‰¹é‡æ’å…¥ Tags (ON CONFLICT DO UPDATE)
                    #    - polymarket_id: å”¯ä¸€çº¦æŸï¼Œç”¨äºå»é‡å’Œå…³è”
                    #    - name: å­˜ slugï¼Œä¾¿äºè°ƒè¯•/å±•ç¤º
                    #    - å¦‚æœ polymarket_id å·²å­˜åœ¨ï¼Œæ›´æ–° nameï¼ˆä»¥é˜² slug å˜åŒ–ï¼‰
                    tag_insert_stmt = insert(Tag).values(
                        [
                            {
                                "polymarket_id": poly_id,
                                "name": all_tags[poly_id],
                            }
                            for poly_id in sorted_poly_ids
                        ]
                    )
                    await session.execute(
                        tag_insert_stmt.on_conflict_do_update(
                            index_elements=["polymarket_id"],
                            set_={"name": tag_insert_stmt.excluded.name},
                        )
                    )

                    # 4. æ‰¹é‡æŸ¥å‡ºæ‰€æœ‰ Tags çš„ IDï¼ˆé€šè¿‡ polymarket_idï¼‰
                    tag_stmt = select(Tag.polymarket_id, Tag.id).where(
                        Tag.polymarket_id.in_(sorted_poly_ids)
                    )
                    tag_results = await session.execute(tag_stmt)
                    for poly_id, tag_id in tag_results.all():
                        tag_map[poly_id] = tag_id

                # =================================================
                # ç¬¬äºŒæ­¥ï¼šå¤„ç† EventCard å’Œ EventSnapshot
                # =================================================
                for event in events_data:
                    poly_id = str(event.get("id"))
                    
                    # å­—æ®µæ¸…æ´—
                    image_url = event.get("image") or event.get("icon")
                    try:
                        volume = float(event.get("volume") or 0)
                    except:
                        volume = 0.0
                    
                    end_date = None
                    if event.get("endDate"):
                        try:
                            end_date = datetime.fromisoformat(event.get("endDate").replace("Z", "+00:00"))
                        except:
                            pass

                    # æ·»åŠ å¿«ç…§
                    session.add(EventSnapshot(polymarket_id=poly_id, raw_data=event))

                    # Upsert EventCard
                    stmt = (
                        insert(EventCard)
                        .values(
                            polymarket_id=poly_id,
                            title=event.get("title", "No Title"),
                            slug=event.get("slug", poly_id),
                            description=event.get("description"),
                            image_url=image_url,
                            volume=volume,
                            end_date=end_date,
                            is_active=event.get("active", True),
                            updated_at=datetime.utcnow(),
                        )
                        .on_conflict_do_update(
                            index_elements=["polymarket_id"],
                            set_={
                                "title": event.get("title"),
                                "volume": volume,
                                "updated_at": datetime.utcnow(),
                                "image_url": image_url,
                                "is_active": event.get("active", True)
                            },
                        )
                    )
                    
                    # è·å– Card ID
                    result = await session.execute(stmt.returning(EventCard.id))
                    card_id = result.scalar_one()
                    event_card_ids[poly_id] = card_id

                # =================================================
                # ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡æ’å…¥å…³è”å…³ç³» (ä½¿ç”¨ tag_map)
                # =================================================
                card_tag_links = []
                for event in events_data:
                    poly_id = str(event.get("id"))
                    card_id = event_card_ids.get(poly_id)
                    if not card_id:
                        continue
                    
                    for tag_data in event.get("tags", []):
                        poly_tag_id = tag_data.get("id")
                        if poly_tag_id is None:
                            continue
                        poly_tag_id_str = str(poly_tag_id)
                        if poly_tag_id_str in tag_map:
                            card_tag_links.append({
                                "card_id": card_id,
                                "tag_id": tag_map[poly_tag_id_str],
                            })
                
                # æ‰¹é‡æ’å…¥å…³è” (å¿½ç•¥å†²çª)
                if card_tag_links:
                    await session.execute(
                        insert(CardTag).values(card_tag_links).on_conflict_do_nothing()
                    )

                # æäº¤äº‹åŠ¡
                await session.commit()
                t_commit = time.time()
                
                # ç®—ä¸€ä¸‹è¿™ä¸€æ‰¹çš„å¹³å‡è€—æ—¶
                total_time = t_commit - t_start
                print(f"   ğŸ’¾ [æ•°æ®åº“] å†™å…¥ {len(events_data)} æ¡ | è€—æ—¶: {total_time:.2f}s")

            except Exception as e:
                await session.rollback()
                # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯å †æ ˆï¼Œæ–¹ä¾¿è°ƒè¯•
                print(f"âŒ å…¥åº“æ‰¹æ¬¡å¤±è´¥: {str(e)}")
                return  # ä¸»æµç¨‹å¤±è´¥æ—¶ä¸è¿›è¡Œ AI åˆ†æ

        # =================================================
        # ç¬¬å››æ­¥ï¼šAI åˆ†æ (ç‹¬ç«‹äº‹åŠ¡å¤„ç†)
        # =================================================
        # åªæœ‰åœ¨ä¸»æµç¨‹æˆåŠŸåï¼Œå¹¶ä¸”æ”¶é›†åˆ°äº† card_ids æ—¶æ‰è¿›è¡Œ
        if event_card_ids:
            await self._process_ai_analysis(events_data, event_card_ids)

    async def _process_ai_analysis(self, events_data: List[Dict[str, Any]], event_card_ids: Dict[str, int]):
        """
        [å†…éƒ¨æ–¹æ³•] å¯¹çˆ¬å–çš„äº‹ä»¶è¿›è¡Œ AI åˆ†æå¹¶ä¿å­˜ç»“æœ
        æ³¨æ„ï¼šä½¿ç”¨ç‹¬ç«‹çš„ sessionï¼Œå¹¶ä¸”ä¸ºäº†é¿å… API é™æµï¼Œä¸²è¡Œå¤„ç†
        """
        # å¦‚æœæ²¡æœ‰é…ç½® GEMINI_API_KEYï¼Œè·³è¿‡
        if not ai_analyzer.api_key:
            return

        async with async_session_factory() as session:
            try:
                for event in events_data:
                    poly_id = str(event.get("id"))
                    card_id = event_card_ids.get(poly_id)
                    
                    if not card_id:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å…³è”å¸‚åœº
                    markets = event.get("markets", [])
                    if not markets:
                        continue
                    
                    # æ„å»ºäº‹ä»¶æ•°æ®
                    event_data_for_ai = {
                        "title": event.get("title", ""),
                        "description": event.get("description", ""),
                        "markets": markets
                    }
                    
                    # è°ƒç”¨ AI åˆ†æ (ä¸²è¡Œæ‰§è¡Œä»¥ä¿æŠ¤ API é™æµ)
                    try:
                        # ç¨å¾®å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                        await asyncio.sleep(0.5)
                        ai_result = await ai_analyzer.analyze_event(event_data_for_ai)
                    except Exception as e:
                        print(f"   âš ï¸ AI åˆ†æå‡ºé”™ ({poly_id}): {e}")
                        continue
                        
                    if not ai_result:
                        continue
                        
                    # è§£æ AI ç»“æœ
                    summary = ai_result.get("executive_summary", "No summary available")
                    markets_data = ai_result.get("markets", {})
                    
                    # æ‰¾åˆ°ä¸»è¦é¢„æµ‹ (æœ€é«˜ confidence)
                    primary_prediction = "0"
                    primary_conf = 0.0
                    
                    for mid, mdata in markets_data.items():
                        conf = mdata.get("confidence_score", 0)
                        if conf > primary_conf:
                            primary_conf = conf
                            odds = mdata.get("ai_calibrated_odds", 0) * 100
                            primary_prediction = f"{odds:.1f}"
                    
                    # è½¬æ¢ raw_analysis æ ¼å¼
                    raw_analysis = ai_analyzer.transform_to_raw_analysis(ai_result)
                    
                    # è¡¥å……åŸå§‹æ•°æ®åˆ° raw_analysis
                    for market in markets:
                        m_id = str(market.get("id", ""))
                        if m_id in raw_analysis:
                            raw_analysis[m_id]["question"] = market.get("question", "")
                            outcome_prices = market.get("outcomePrices", [])
                            if outcome_prices:
                                try:
                                    if isinstance(outcome_prices, str):
                                        outcome_prices = json.loads(outcome_prices)
                                    if outcome_prices:
                                        raw_analysis[m_id]["original_odds"] = float(outcome_prices[0])
                                except (json.JSONDecodeError, ValueError, IndexError):
                                    pass
                    
                    # å­˜å…¥æ•°æ®åº“ï¼šå…ˆåˆ é™¤æ—§çš„é¢„æµ‹
                    await session.execute(
                        delete(AIPrediction).where(AIPrediction.card_id == card_id)
                    )
                    
                    new_prediction = AIPrediction(
                        card_id=card_id,
                        summary=summary,
                        outcome_prediction=primary_prediction,
                        confidence_score=min(primary_conf * 10, 99.99),  # è½¬ä¸º 0-100
                        raw_analysis=json.dumps(raw_analysis, ensure_ascii=False)
                    )
                    session.add(new_prediction)
                    print(f"   ğŸ¤– AI åˆ†æå®Œæˆ: {event.get('title', '')[:30]}...")
                
                await session.commit()
                
            except Exception as e:
                await session.rollback()
                print(f"âŒ AI åˆ†ææ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")

    async def close(self):
        await self.client.aclose()


# -------------------------------------------------
# ğŸš€ æé€Ÿå¹¶å‘æ‰§è¡Œå…¥å£
# -------------------------------------------------
async def process_batch_task(crawler, offset, semaphore):
    """å•ä¸ªæ‰¹æ¬¡ä»»åŠ¡"""
    async with semaphore:
        data = await crawler.fetch_page(limit=50, offset=offset)
        
        # ğŸ‘‡ åŠ è¿™è¡Œæ—¥å¿—
        print(f"ğŸ“„ Offset {offset}: æŠ“åˆ° {len(data)} æ¡æ•°æ®")
        
        if not data:
            return 0
        await crawler.save_batch(data)
        return len(data)

async def run_batch_crawl():
    crawler = PolymarketCrawler()
    
    # --- å‚æ•°é…ç½® ---
    TOTAL_TARGET = 1000   # ç›®æ ‡æŠ“å–æ•°é‡
    BATCH_SIZE = 50       # æ¯é¡µæ•°é‡
    CONCURRENCY = 5       # ğŸ”¥ å¹¶å‘æ•°ï¼šåŒæ—¶å‘ 5 ä¸ªè¯·æ±‚
    
    print(f"ğŸš€ å¯åŠ¨æé€Ÿçˆ¬è™« | ç›®æ ‡: {TOTAL_TARGET} | å¹¶å‘: {CONCURRENCY}")
    
    semaphore = asyncio.Semaphore(CONCURRENCY)
    offsets = range(0, TOTAL_TARGET, BATCH_SIZE)
    
    tasks = []
    for offset in offsets:
        task = process_batch_task(crawler, offset, semaphore)
        tasks.append(task)
    
    try:
        t_start = time.time()
        results = await asyncio.gather(*tasks)
        t_end = time.time()
        
        total = sum(results)
        print("-" * 40)
        print(f"ğŸ‰ ä»»åŠ¡ç»“æŸï¼å…±å¤„ç† {total} æ¡æ•°æ®")
        print(f"â±ï¸ æ€»è€—æ—¶: {t_end - t_start:.2f}s")
        print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {total / (t_end - t_start):.2f} æ¡/ç§’")
            
    finally:
        await crawler.close()

if __name__ == "__main__":
    asyncio.run(run_batch_crawl())