"""
Gemini AI Analyzer Service
ä½¿ç”¨ Google Gemini è¿›è¡Œäº‹ä»¶åˆ†æå’Œæ¦‚ç‡æ ¡å‡†
"""

import os
import re
import json
import asyncio
import logging
from datetime import datetime
from typing import Optional, Dict, Any

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

logger = logging.getLogger(__name__)


def _fix_json_string(text: str) -> str:
    """
    å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
    """
    # 1. ç§»é™¤ markdown ä»£ç å—æ ‡è®°
    text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'^```\s*$', '', text, flags=re.MULTILINE)
    text = text.strip()
    
    # 2. ç§»é™¤å°¾éƒ¨é€—å· (trailing commas)
    text = re.sub(r',(\s*[}\]])', r'\1', text)
    
    # 3. ä¿®å¤å•å¼•å·ä¸ºåŒå¼•å· (ç®€å•æƒ…å†µ)
    # æ³¨æ„ï¼šè¿™æ˜¯ç²—æš´å¤„ç†ï¼Œå¯èƒ½åœ¨æŸäº›è¾¹ç¼˜æƒ…å†µå¤±æ•ˆ
    
    return text


class GeminiAnalyzer:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logger.warning("âš ï¸ GEMINI_API_KEY not set. AI analysis will fail.")
        else:
            genai.configure(api_key=self.api_key)

    def _get_model(self):
        """é…ç½® Gemini æ¨¡å‹"""
        generation_config = {
            "temperature": 0.7,
            "response_mime_type": "application/json",  # å¼ºåˆ¶è¾“å‡º JSON
        }

        return genai.GenerativeModel(
            model_name="gemini-2.0-flash",  # ç¨³å®šå¯ç”¨çš„æ¨¡å‹
            generation_config=generation_config,
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )

    def _get_market_probability(self, market: Dict[str, Any]) -> float:
        """æå–å¸‚åœºæ¦‚ç‡ï¼ˆç»Ÿä¸€é€»è¾‘ï¼‰"""
        if "calculated_odds" in market:
            return float(market["calculated_odds"])
        
        outcome_prices = market.get("outcomePrices", [])
        if outcome_prices:
            try:
                if isinstance(outcome_prices, str):
                    outcome_prices = json.loads(outcome_prices)
                return float(outcome_prices[0])
            except:
                pass
        
        return float(market.get("probability", 0.0))

    def _construct_prompt(self, event_data: Dict[str, Any]) -> str:
        """
        æ„å»º Prompt (V5ï¼š5% å‡†å…¥é—¨æ§› + å®¡è®¡å‘˜æ¨¡å¼)
        """
        current_time = datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")
        
        # 1. ä¸¥æ ¼çš„ 5% å¸‚åœºå‡†å…¥è¿‡æ»¤
        MIN_PROBABILITY_THRESHOLD = 0.05  # 5% é—¨æ§›
        markets = event_data.get("markets", [])
        
        markets_text = ""
        filtered_count = 0
        for m in markets:
            probability = self._get_market_probability(m)
            
            # ä¸¥æ ¼éµå®ˆ 5% é—¨æ§›ï¼Œä½äºæ­¤å€¼ä¸è¿›å…¥ AI åˆ†ææ± 
            if probability < MIN_PROBABILITY_THRESHOLD:
                filtered_count += 1
                continue
            
            market_id = m.get("id", m.get("polymarket_id", ""))
            question = m.get("question", "")
            
            # æ ¼å¼åŒ–ï¼šåŒæ—¶æ˜¾ç¤º 0.65 å’Œ 65.0%
            markets_text += f"""
            - Market ID: {market_id}
            - Question: {question}
            - Current Probability: {probability:.2f} ({probability*100:.1f}%)
            """
        
        if filtered_count > 0:
            logger.info(f"ğŸ“Š è¿‡æ»¤æ‰ {filtered_count} ä¸ªä½æ¦‚ç‡å¸‚åœº (< 5%)")

        # 2. V4 æ ¸å¿ƒ Promptï¼šå®¡è®¡å‘˜ + é”šå®šæ•ˆåº” + ä¸¥æ ¼çº¦æŸ
        prompt = f"""
        Role: You are a Senior Risk Manager at a Hedge Fund. 
        Current Time: {current_time}

        Task: AUDIT the current prediction market odds. 
        **CRITICAL RULE**: The market is "Efficient" by default. The Current Probability is your STARTING ANCHOR. 
        Do NOT invent a probability from scratch. You only adjust the market price up or down based on "Alpha" (new information the market hasn't priced in).

        Input Event:
        Title: {event_data.get("title", "")}
        Description: {event_data.get("description", "")}
        
        **IMPORTANT MATHEMATICAL CONSTRAINT**: The following markets are MUTUALLY EXCLUSIVE and part of the same event. The sum of your ai_calibrated_odds for all listed Market IDs MUST EQUAL 1.0 (100%). If you assign a high probability to one date, you must reduce others proportionally.
        
        Markets:
        {markets_text}

        Analysis Framework (The "Delta" Method):
        1. **Start with Market Odds**.
        2. **Search for Contradictions**: Is there breaking news, injury reports, or legal filings that the market ignores?
        3. **Apply Adjustment**:
           - No new info? -> Keep AI Odds close to Market Odds (e.g., Market 65% -> AI 63-67%).
           - Minor friction? -> Small adjustment (e.g., -5%).
           - "Smoking Gun" (Fatal flaw)? -> Large adjustment (e.g., -20%).
           
        **Sanity Check**: 
        - If Market Odds > 60% and you predict < 10%, YOU ARE LIKELY WRONG unless the team has been disqualified or the event cancelled. 
        - Do not be overly conservative just because the event is far in the future.

        Analysis Requirements (The "Auditor" Standard):
        1. **Executive Summary**: One ruthless sentence (max 20 words) citing the biggest macro-factor (e.g., "Fed Rate Cut", "QB Injury", "SEC Deadline").

        2. **For EACH Market**, provide a forensic breakdown:
           
           - **Structural Anchor (The Baseline)**: 
             * State the base assumption supporting the current price. 
             * Example: "Market prices in dominant 12-win season performance."
           
           - **The Noise (Overreaction)**: 
             * What SPECIFIC headline/hype is inflating the price?
             * â›” BAD: "Sentiment is mixed."
             * âœ… GOOD: "Viral rumors about a settlement on Twitter are ignoring the judge's latest scheduling order."
           
           - **The Barrier (The Risk)**: 
             * Specific hurdle (Injury, Law, Math).
             * âœ… GOOD: "Cap space is -$15M, preventing key signings."
           
           - **The Blindspot (The Edge)**: 
             * What specific data is the crowd missing?
           
           - **Calibrated Probability**: 
             * YOUR FINAL ADJUSTED ODDS (0.0 - 1.0). 
             * **Must be relative to the original odds.**
           
           - **Confidence**: 0-10 (How confident are you in your *deviation* from the market?).

        OUTPUT FORMAT (Strict JSON):
        {{
            "executive_summary": "string",
            "markets": {{
                "MARKET_ID_HERE": {{
                    "ai_calibrated_odds": 0.65, 
                    "confidence_score": 8.5,
                    "analysis": {{
                        "structural_anchor": "string",
                        "noise": "string",
                        "barrier": "string",
                        "blindspot": "string"
                    }}
                }}
            }}
        }}
        """
        return prompt

    def analyze_with_gemini(self, event_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        åŒæ­¥ç‰ˆæœ¬ï¼šåˆ†æå•ä¸ªäº‹ä»¶ï¼ˆå¸¦è¾“å…¥è¾“å‡ºå®¡è®¡æ—¥å¿—ï¼‰
        """
        if not self.api_key:
            logger.error("âŒ GEMINI_API_KEY not configured")
            return None

        model = self._get_model()
        prompt = self._construct_prompt(event_data)

        # --- [æ£€ç´¢ç‚¹ 1: è¾“å…¥å®¡è®¡] ---
        logger.debug(f"===== AI INPUT PROMPT (Event: {event_data.get('id')}) =====")
        logger.debug(prompt)

        try:
            response = model.generate_content(prompt)
            raw_response = response.text

            # --- [æ£€ç´¢ç‚¹ 2: è¾“å‡ºå®¡è®¡] ---
            logger.debug(f"===== AI RAW RESPONSE =====")
            logger.debug(raw_response)

            # å°è¯•è§£æ JSON
            try:
                parsed_data = json.loads(raw_response)
                return parsed_data
            except json.JSONDecodeError:
                # å°è¯•ä¿®å¤å¹¶é‡æ–°è§£æ
                fixed_text = _fix_json_string(raw_response)
                try:
                    parsed_data = json.loads(fixed_text)
                    logger.warning("âš ï¸ JSON was malformed, auto-fixed successfully")
                    return parsed_data
                except json.JSONDecodeError as e:
                    logger.error(f"è§£æ AI å›å¤å¤±è´¥: {e}, åŸå§‹æ–‡æœ¬: {raw_response}")
                    return None
        except Exception as e:
            logger.error(f"Gemini API è°ƒç”¨å¤±è´¥: {e}")
            return None

    async def analyze_event(self, event_data: Dict[str, Any], max_retries: int = 3, retry_delay: float = 2.0) -> Optional[Dict[str, Any]]:
        """
        ä¸»å…¥å£ï¼šåˆ†æå•ä¸ªäº‹ä»¶ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            event_data: åŒ…å« title, description, markets ç­‰å­—æ®µçš„äº‹ä»¶æ•°æ®
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ 3 æ¬¡
            retry_delay: é‡è¯•é—´éš”ç§’æ•°ï¼Œé»˜è®¤ 2 ç§’
            
        Returns:
            åˆ†æç»“æœå­—å…¸ï¼Œæ ¼å¼ï¼š
            {
                "executive_summary": "...",
                "markets": {
                    "market_id": {
                        "ai_calibrated_odds": 0.55,
                        "confidence_score": 8.5,
                        "analysis": {
                            "structural_anchor": "...",
                            "noise": "...",
                            "barrier": "...",
                            "blindspot": "..."
                        }
                    }
                }
            }
        """
        if not self.api_key:
            logger.error("âŒ GEMINI_API_KEY not configured")
            return None

        event_title = event_data.get("title", "Unknown")
        model = self._get_model()
        prompt = self._construct_prompt(event_data)
        
        last_error = None
        
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"ğŸ¤– Calling Gemini for: {event_title[:30]}... (attempt {attempt}/{max_retries})")
                
                # å¼‚æ­¥è°ƒç”¨ Gemini
                response = await model.generate_content_async(prompt)
                
                # è§£æ JSON (å¸¦å®¹é”™)
                raw_text = response.text
                try:
                    result_json = json.loads(raw_text)
                except json.JSONDecodeError:
                    # å°è¯•ä¿®å¤å¹¶é‡æ–°è§£æ
                    fixed_text = _fix_json_string(raw_text)
                    try:
                        result_json = json.loads(fixed_text)
                        logger.warning("âš ï¸ JSON was malformed, auto-fixed successfully")
                    except json.JSONDecodeError as e2:
                        # JSON è§£æå¤±è´¥ï¼Œè®°å½•å¹¶é‡è¯•
                        logger.warning(f"âš ï¸ JSON parse failed (attempt {attempt}): {e2}")
                        last_error = e2
                        if attempt < max_retries:
                            await asyncio.sleep(retry_delay)
                        continue
                
                logger.info("âœ… Gemini analysis complete.")
                return result_json

            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ Gemini call failed (attempt {attempt}): {e}")
                if attempt < max_retries:
                    await asyncio.sleep(retry_delay)
                continue
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        logger.error(f"âŒ Gemini Analysis Failed after {max_retries} attempts: {last_error}")
        return None

    def _should_normalize(self, event_title: str, market_count: int) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦å¯¹æ¦‚ç‡è¿›è¡Œå½’ä¸€åŒ–ï¼ˆæ€»å’Œ = 100%ï¼‰
        
        è·³è¿‡å½’ä¸€åŒ–çš„åœºæ™¯ï¼š
        - ç´¯ç§¯å‹äº‹ä»¶ï¼ˆæ ‡é¢˜å« by, hit, reach, above, below, over, under ç­‰ï¼‰
        - å•ä¸€å¸‚åœºï¼ˆmarket_count == 1ï¼‰
        
        æ‰§è¡Œå½’ä¸€åŒ–çš„åœºæ™¯ï¼š
        - ç«äº‰æ€§å¤šé€‰ä¸€ï¼ˆæ ‡é¢˜å« nominee, winner, which, who will ç­‰ï¼‰
        """
        title_lower = (event_title or "").lower()
        
        # 1. å•ä¸€å¸‚åœºï¼šè·³è¿‡å½’ä¸€åŒ–
        if market_count <= 1:
            logger.info("ğŸ“Š å•ä¸€å¸‚åœºï¼Œè·³è¿‡å½’ä¸€åŒ–")
            return False
        
        # 2. ç´¯ç§¯å‹å…³é”®è¯ï¼šè·³è¿‡å½’ä¸€åŒ–ï¼ˆä¿ç•™ AI åŸå§‹åå·®ä¿¡å·ï¼‰
        cumulative_keywords = [
            " by ", "hit", "reach", "above", "below", "over", "under",
            "at least", "more than", "less than", "exceed", "surpass"
        ]
        for kw in cumulative_keywords:
            if kw in title_lower:
                logger.info(f"ğŸ“Š ç´¯ç§¯å‹äº‹ä»¶ (å« '{kw}')ï¼Œè·³è¿‡å½’ä¸€åŒ–")
                return False
        
        # 3. ç«äº‰æ€§å…³é”®è¯ï¼šæ‰§è¡Œå½’ä¸€åŒ–
        competitive_keywords = [
            "nominee", "winner", "which", "who will win", "who will be",
            "next president", "next prime minister", "champion"
        ]
        for kw in competitive_keywords:
            if kw in title_lower:
                logger.info(f"ğŸ“Š ç«äº‰æ€§äº‹ä»¶ (å« '{kw}')ï¼Œæ‰§è¡Œå½’ä¸€åŒ–")
                return True
        
        # 4. é»˜è®¤ï¼šå¤šå¸‚åœºæ‰§è¡Œå½’ä¸€åŒ–
        logger.info(f"ğŸ“Š å¤šå¸‚åœº ({market_count} ä¸ª)ï¼Œé»˜è®¤æ‰§è¡Œå½’ä¸€åŒ–")
        return True

    def transform_to_raw_analysis(
        self, 
        gemini_result: Dict[str, Any], 
        original_markets: list = None,
        event_title: str = None
    ) -> Dict[str, Any]:
        """
        å°† Gemini è¿”å›ç»“æœè½¬æ¢ä¸º raw_analysis å­˜å‚¨æ ¼å¼ï¼ˆæ™ºèƒ½å½’ä¸€åŒ–ï¼‰
        
        Args:
            gemini_result: Gemini API è¿”å›çš„åŸå§‹ç»“æœ
            original_markets: åŸå§‹å¸‚åœºåˆ—è¡¨ï¼ˆåŒ…å«æœªè¿›å…¥ AI åˆ†ææ± çš„å¸‚åœºï¼‰
            event_title: äº‹ä»¶æ ‡é¢˜ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å½’ä¸€åŒ–ï¼‰
            
        Returns:
            é€‚åˆå­˜å…¥ AIPrediction.raw_analysis çš„æ ¼å¼
        """
        if not gemini_result:
            return {}
        
        ai_markets = gemini_result.get("markets", {})
        original_markets = original_markets or []
        
        # 1. æ”¶é›†æ‰€æœ‰åŸå§‹å¸‚åœºçš„æ¦‚ç‡
        all_market_probs = {}
        for m in original_markets:
            market_id = m.get("id", m.get("polymarket_id", ""))
            prob = self._get_market_probability(m)
            all_market_probs[market_id] = prob
        
        # 2. è®¡ç®— AI è¿”å›çš„æ¦‚ç‡æ€»å’Œ
        total_ai_prob = sum(m.get("ai_calibrated_odds", 0) for m in ai_markets.values())
        
        # 3. åˆ¤æ–­æ˜¯å¦éœ€è¦å½’ä¸€åŒ–
        should_normalize = self._should_normalize(event_title, len(original_markets))
        
        # 4. è®¡ç®—æœªåˆ†æå¸‚åœºçš„åŸå§‹æ¦‚ç‡æ€»å’Œ
        analyzed_ids = set(ai_markets.keys())
        unanalyzed_prob_sum = sum(
            prob for mid, prob in all_market_probs.items() 
            if mid not in analyzed_ids
        )
        
        # 5. ç¡®å®šå½’ä¸€åŒ–åŸºå‡†
        if should_normalize:
            normalization_base = total_ai_prob + unanalyzed_prob_sum
            if normalization_base <= 0:
                normalization_base = 1.0
            if abs(normalization_base - 1.0) > 0.01:
                logger.warning(f"âš ï¸ AI æ¦‚ç‡æ€»å’Œä¸º {normalization_base:.3f}ï¼Œå°†å¼ºåˆ¶å½’ä¸€åŒ–åˆ° 1.0")
        else:
            # ä¸å½’ä¸€åŒ–ï¼šç›´æ¥ä½¿ç”¨ AI åŸå§‹å€¼ï¼ˆä¹˜ä»¥ 100 è½¬ä¸ºç™¾åˆ†æ¯”ï¼‰
            normalization_base = 1.0
        
        raw_analysis = {}
        
        # 6. å¤„ç† AI åˆ†æè¿‡çš„å¸‚åœº
        for market_id, market_data in ai_markets.items():
            analysis = market_data.get("analysis", {})
            calibrated_prob = market_data.get("ai_calibrated_odds", 0)
            
            if should_normalize:
                final_pct = (calibrated_prob / normalization_base) * 100
            else:
                # ä¸å½’ä¸€åŒ–ï¼šç›´æ¥è½¬ä¸ºç™¾åˆ†æ¯”
                final_pct = calibrated_prob * 100
            
            raw_analysis[market_id] = {
                "ai_calibrated_odds_pct": round(final_pct, 2),
                "ai_confidence": market_data.get("confidence_score", 0),
                "structural_anchor": analysis.get("structural_anchor"),
                "noise": analysis.get("noise"),
                "barrier": analysis.get("barrier"),
                "blindspot": analysis.get("blindspot"),
                "_analyzed": True,
                "_normalized": should_normalize,
            }
        
        # 7. å¤„ç†æœªåˆ†æçš„å¸‚åœºï¼ˆä½äº 5% é—¨æ§›ï¼‰
        for market_id, original_prob in all_market_probs.items():
            if market_id not in analyzed_ids:
                if should_normalize:
                    final_pct = (original_prob / normalization_base) * 100
                else:
                    final_pct = original_prob * 100
                
                raw_analysis[market_id] = {
                    "ai_calibrated_odds_pct": round(final_pct, 2),
                    "ai_confidence": 0,
                    "structural_anchor": None,
                    "noise": None,
                    "barrier": None,
                    "blindspot": None,
                    "_analyzed": False,
                    "_normalized": should_normalize,
                }
        
        return raw_analysis


# å•ä¾‹æ¨¡å¼
ai_analyzer = GeminiAnalyzer()
